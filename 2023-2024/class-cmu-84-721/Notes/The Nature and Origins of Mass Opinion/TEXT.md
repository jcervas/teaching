Zaller, John R. 1992. The Nature and Origins of Mass Opinion. Cambridge: Cambridge University Press. https://www.cambridge.org/core/books/nature-and-origins-of-mass-opinion/70B1485D3A9CFF55ADCCDD42FC7E926A.

FULL TEXT (no footnotes or tables)

# Chapter 2: Information, predispositions, and opinion

Every opinion is a marriage of information and predisposition: information to form a mental picture of the given issue, and predisposition to motivate some conclusion about it. The central aim of this book is to show how, across a very wide range of issues, variations in the information carried in elite discourse, individual differences in attention to this information, and individual differences in political values and other predispositions jointly determine the contours of public opinion. The book, thus, is most crucially about the relationship among information, predispositions, and opinion. The present chapter introduces and defines these key terms, examines some critical problems associated with their study, and shows in a preliminary way how they relate to one another. In so doing, it develops the intuitions behind the more technical core of the book, which begins in Chapter 3. 

## INFORMATION AND ELITE DISCOURSE

To an extent that few like but none can avoid, citizens in large societies are dependent on unseen and usually unknown others for most of their information about the larger world in which they live. As Walter Lippmann wrote in his classic treatise, Public Opinion (1922/1946), Each of us lives and works on a small part of the earth's surface, moves in a small circle, and of these acquaintances knows only a few intimately. Of any public event that has wide effects we see at best only a phase and an aspect. . . . Inevitably our opinions cover a bigger space, a longer reach of time, a greater number of things, than we can directly observe. They have, therefore, to be pieced together out of what others have reported and what we can imagine, (p. 59) The "others" on whom we depend, directly or indirectly, for information about the world are, for the most part, persons who devote themselves full time to some aspect of politics or public affairs - which is to say, political elites. These elites include politicians, higher-level government officials, journalists, some activists, and many kinds of experts and policy specialists. Even when we learn from friends or family members about some aspect of public affairs, often we may still be secondhand consumers of ideas that originated more distantly among some type of elite.The information that reaches the public is never a full record of important events and developments in the world. It is, rather, a highly selective and stereotyped view of what has taken place. It could hardly be otherwise. But even if it could, the public would have little desire to be kept closely informed about the vast world beyond its personal experience. It requires news presentations that are short, simple, and highly thematic - in a word, stereotyped. Thus, Doris Graber (1984), in a close study of how a sample of citizens monitored the news, found that her subjects ' 'grumbled frequently about the oversimplified treatment of [television] news ..." Yet when special news programs and newspaper features presented a small opportunity for more extensive exposure to issues, they were unwilling to seize it. For the most part, [citizens] would not read and study carefully the more extensive versions of election and other news in newspapers and news magazines. Masses of specific facts and statistics were uniformly characterized as dull, confusing, and unduly detailed. ... (p. 105) Lippmann, who remains perhaps the most insightful analyst of the process by which the public comes to form an understanding of complex and distant events, devoted a large section of Public Opinion to news stereotypes, or what today are more often called frames of reference. In one lucid passage, he described World War I as it would probably have been perceived by a character in Sinclair Lewis's Main Street: Miss Sherwin of Gopher Prairie is aware that a war is raging in France and tries to conceive it. She has never been to France, and certainly she has never been along what is now the battlefront. Pictures of France and German soldiers she has seen, but it is impossible for her to imagine three million men. No one, in fact, can imagine them, and professionals do not try. They think of them as, say, two hundred divisions. But Miss Sherwin has no access to the order of battle maps, and if she is to think about the war, she fastens upon Joffre and the Kaiser as if they were engaged in a personal duel. Perhaps if you could see what she sees with her mind's eye, the image in its composition might be not unlike an Eighteenth Century engraving of a great soldier. He stands there boldly unruffled and more than life size, with a shadowy army of tiny little figures winding off into the landscape behind, (p. 8) As suggested by Miss Sherwin's reliance on an eighteenth-century engraving, Lippmann doubted that individuals can personally create the stereotypes and other symbolic representations - "the pictures in our heads" - by which remote and even proximate events are understood. Rather, [i]n the great blooming, buzzing confusion of the outer world we pick out what our culture has already defined for us, and we tend to perceive that which we have picked out in the form stereotyped for us by our culture, (p. 61) Many of the stereotypes to which Lippmann refers are permanent features of the culture - the corrupt politician, the labor strike, the election contest, the yeoman farmer. But because society is always churning up new issues and problems, many stereotypes are recent creations. For example, research has shown how, in the debate over the Equal Rights Amendment, stereotypes of unisex toilets and women combat troops came into being as a reflection of the organizational and ideological needs of the contending activists (Mansbridge, 1986). Luker has done similar research on the origins of the Pro-Choice and ProLife labels in the contrasting world views of abortion activists (Luker, 1984). A powerful stereotype that has emerged in recent years is that of "the homeless." Stereotypes and frames like these are important to the process by which the public keeps informed because they determine what the public thinks it is becoming informed about, which in turn often determines how people take sides on political issues (Edelman, 1964; Bennett, 1980; Gamson and Modigliani, 1987; Kinder and Sanders, 1990). Although culturally given and elite-supplied stereotypes may be most powerful in shaping public understanding of events that are "out of reach, out of sight, out of mind" (Lippmann, 1922/1946, p. 21), they can be important even for matters within people's powers of direct observation. For example, Iyengar (1991) has used experimental evidence to argue that whether television news focuses on "episodic" cases of individual poverty, or the societywide conditions that cause poverty, affects the public's attribution of blame for poverty and thereby its willingness to support programs aimed at alleviating it. Perhaps the most fundamental question about news stereotypes, or frames of reference, is whether the public is given any choice about them - whether, that is, it is permitted to choose between alternative visions of what the issue is. For in the absence of such choice, the public can do little more than follow the elite consensus on what should be done. For example, in the early phase of American involvement in the Vietnam War, the public was offered only one way to think about the war, namely as a struggle to preserve freedom by "containing Communism." Even news stories that criticized government policy did so within a framework that assumed the paramount importance of winning the war and defeating communism (Halberstam, 1979; Hallin, 1986). During this period, public support for American involvement in the war was very strong, and those members of the public most heavily exposed to the mass media supported the "official line" most strongly. In the later phase of the war, however, journalists began to present information in ways suggesting that it was essentially a civil war among contending Vietnamese factions and hence both inessential to U.S. security interests and also perhaps unwinnable. Coverage implicitly supportive of the war continued, but it no longer had near-monopoly status. Owing, as I show in Chapter 9, to this change in media coverage, public support for the war weakened greatly. Also, heavy exposure to the mass media was no longer associated with support for the war, but with a polarization of opinion that reflected the division in political discourse. Politically attentive liberals within the general public tended to adopt the position taken by elites conventionally recognized as liberal, while politically attentive conservatives in the general public moved toward the position of conservative opinion leaders. So, when elites uphold a clear picture of what should be done, the public tends to see events from that point of view, with the most politically attentive members of the public most likely to adopt the elite position. When elites divide, members of the public tend to follow the elites sharing their general ideological or partisan predisposition, with the most politically attentive members of the public mirroring most sharply the ideological divisions among the elite. These claims about the effects of elite discourse, which are an important part of what this book will attempt to demonstrate, are obviously quite strong ones. By way of further preliminary examination, I would like to give an overview of the evolution of American racial attitudes in the twentieth century. I strongly emphasize that my purpose in reviewing this sensitive subject is not to convince anyone of the final correctness of my view, but only to illustrate as clearly as possible the general vision that underlies the more specific arguments of later chapters.

### Elite discourse and racial attitudes

At the turn of the century, the United States was a deeply racist society - not only in the caste structure of the southern states and in the widespread practice of discrimination, but in the political ideas that informed elite and mass thinking about race. Although there was some mainstream elite disagreement on the subject of race, it was confined to a very narrow range. Virtually all white elites accepted some notion of the inferiority of other racial groups (Fredrickson, 1971). It is both distasteful and unnecessary to recount these ideas, but one point is important to the argument I wish to make. It is that racist ideas about blacks and, indeed, about most non-Anglo-Saxon groups, including Asians, southern and eastern Europeans, and Jews - had the support of the biological and psychological science of that period. Racist ideas, thus, were not confined to an extremist or backwater fringe; they were as common among the nation's white intellectual leaders as among other types of whites. Given this pattern of elite attitudes, any attempts to mobilize white support for black equality, whether by blacks themselves or sympathetic whites, were bound to fail. By 1930, however, the attitudes of political elites seemed to be changing. In that year, President Hoover's nomination of John Parker of North Carolina to the Supreme Court was rejected in large part because of a ten-year-old speech in which Parker had said that "The Negro as a class does not desire to enter politics" and that the "participation of the Negro in politics is a source of evil and danger to both races" (cited in Kluger, 1975: p. 142). That a single racist speech, of a type that was entirely conventional throughout the nineteenth and early twentieth centuries, could become a basis for the rejection of a Supreme Court nominee by the Senate was an indication that attitudes toward race were undergoing a historic shift. Despite this, race was apparently not a major public issue in the 1930s (Sheatsley 1966: p. 217). Moreover, Gunnar Myrdal (1944), in his massive investigation of American race relations, found that neither the material condition of blacks nor the amount of discrimination they faced were much different in 1940 than they had been in the immediate aftermath of the Civil War. To the extent that there had been any improvement at all, it was only because some blacks had migrated to the North, where conditions had always been somewhat better. Nonetheless, Myrdal maintained that a period of great racial progress lay just ahead. White Americans believed deeply in their creed of equality and had come to realize that black demands for equality were justified. He therefore thought the days of white resistance to racial equality were near their end. Thus, by MyrdaFs account, which proved extraordinarily prescient, a change in white attitudes preceded any change in the actual conditions of blacks. What, then, brought about the attitude change? One can imagine many possibilities, but Myrdal found the explanation in purely intellectual developments. Scientists, who as recently as 1920 had overwhelmingly endorsed the notion that some racial groups were superior to others, had by their subsequent research discredited it. The magnitude of the change in scientific thinking is captured by the following two passages from the work of Carl Brigham, who was for a time a leading authority on race. In 1923 Brigham concluded his Study of American Intelligence by claiming flatly that "the intellectual superiority of our Nordic group over the Alpine, Mediterranean, and negro groups has been demonstrated" (p. 192). However, in a review of subsequent research that was published just seven years later, Brigham felt compelled to withdraw this conclusion. As he wrote in the final sentence of his paper, This review has summarized some of the more recent test findings which show that comparative studies of various national and racial groups may not be made with existing tests, and which show, in particular, that one of the most pretentious of these comparative racial studies - the author's own - was without foundation. (Brigham, 1930: p. 165) Reviewing this and other research, Myrdal wrote that "A handful of social and biological scientists over the past fifty years have gradually forced informed people to give up some of the more blatant of our biological errors" (p. 92). As Degler (1991) has recently shown, changing scientific theories of race in the 1920s were part of a much larger scientific movement away from biological explanations of human behavior.l With the intellectual defeat of early theories of racial inferiority, psychologists shifted their research to the stigmatizing effects on blacks of what was now taken to be white prejudice, and to the origins of racial prejudice in various kinds of mental disorders and educational deficiencies (Allport, 1954).2 In consequence of all this, the stereotypes used to explain racial differences in material conditions underwent a major change. Until about 1930 these stereotypes stressed racial inferiority as the reason for inequality. Since then the dominant tendency of elite discourse has been to blame inequality either on a failure of individual effort or, in its common liberal variant, on the effects of white discrimination against blacks. A more profound shift in elite discourse can scarcely be imagined. Owing to the lack of opinion data until the late 1930s, the effects on public opinion of this revolution in elite discourse cannot be fully documented. But three points about public opinion are reasonably clear. First, there has been a massive shift toward greater public support by whites for the principle of racial equality. The shift has not extended as far as many would like - most notably, whites have resisted many government efforts to combat discrimination and have been even more opposed to most efforts to make up for the effects of past discrimination. Nor is the sincerity of some people's professions of belief in equality beyond question. But evidence of great change is hard to deny (Schuman, Steeh, and Bobo, 1985). For example, only 45 percent of whites in a 1944 survey said blacks ' 'should have as good a chance as white people to get any kind of job," whereas in 1972, this figure had risen to 97 percent. Similarly, the percentage saying that "white students and black students should go to the same schools" rather than separate ones rose from 32 percent in 1942 to 90 percent in 1982. These changes may have begun to occur at the time of the first mass opinion polls on race in the early 1940s, or the changes may have been already under way at that time. In either case, the shift in mass attitudes roughly coincides with the shift in elite attitudes. Second, the people most heavily exposed to the new elite discourse on race, namely the better educated, have been most likely to support those ideas that constitute the modern elite consensus on race. Thus, the better educated are not especially likely to support affirmative action or the more controversial efforts to combat inequality, such as school busing, which tend not to have consensual elite support; but they do exhibit disproportionate support for the principle of equality and for those efforts to combat discrimination, such as federal laws against segregated restaurants and transportation systems, that do enjoy mainstream elite support (Allport, 1954; Schuman et al., 1985). Thus, exactly as in the Vietnam case described earlier, exposure to elite discourse appears to promote support for the ideas carried in it. (I present further evidence on the racially liberalizing effects of exposure to elite discourse in Chapter 8.) Finally, the public has been responsive to partisan elite cues on the subject of race. The evidence on this point, much of which comes from the recent work of Carmines and Stimson (1989), is worth examining in some detail. Throughout the 1950s and early 1960s, elite Democrats and Republicans exhibited no consistent partisan differences on racial issues. The Democratic Party was home to many prominent racial liberals, most notably Hubert H. Humphrey, and had, under the leadership of President Harry S Truman, pressed to achieve a measure of equality for blacks, especially in the military. Yet racially conservative Southerners remained a major power within the Democratic party. Meanwhile, the Republican President Dwight Eisenhower, though no crusader on race, appointed the racially liberal Earl Warren to be chief justice of the Supreme Court, and used federal troops to enforce its landmark school desegregation decisions. Finally, despite the impression created by such prominent Democratic liberals as Humphrey, Republican congressmen were more liberal than Democrats on race, as shown in Figure 2.1. As a result of this lack of clearly differentiated leadership cues, as Carmines and Stimson argue, Democrats and Republicans in the general public did not differ on racial issues. Beginning in late 1963, however, the Democratic Party, overcoming the resistance of its Southern wing, stepped out as the party of racial liberalism, while the Republican party became the more racially conservative party. Thus, President Lyndon Johnson, as titular leader of his party, pressed for and won major civil rights bills in Congress, while Senator Barry Goldwater, the Republican presidential nominee in 1964, became the most prominent opponent of this legislation. Also, congressional voting on racial issues began to follow closely Democratic-Republican party lines (see upper portion of Figure 2.1). The effect of this change in party leadership cues is apparent in the lower portion of Figure 2.1. Rank-and-file Democrats and Republicans began in 1964 to exhibit substantial amounts of party polarization on racial issues - the result, it would seem, of the sudden change in the structure of party leadership cues.3 There is, however, an ambiguity in these results. Mass polarization along party lines could have come about from a reshuffling of party loyalties, with racial liberals flocking to the Democratic Party and racial conservatives moving over to the Republican side. This is the party conversion thesis. Or polarization could have come about from opinion conversion, that is, existing Democrats becoming more racially liberal and existing Republicans becoming more racially conservative. This is the opinion leadership thesis. Although Carmines and Stimson make no attempt to sort out these competing possibilities, it appears that both processes were at work. Petrocik (1989) has shown that, beginning in 1964, the Democratic Party lost Southern whites and gained blacks, which indicates a reshuffling of party loyalties along lines of preexisting racial opinions. And Gerber and Jackson (1990) have shown that many existing Democrats and Republicans also changed their racial opinions to accord with the new party leadership cues, which indicates a mass response to elite opinion leadership.4 For purposes of this book, the latter phenomenon is the more important. If elite cues can change racial opinions, which appear to be among the most deeply felt of mass opinions (Carmines and Stimson, 1982; Converse, 1964; Converse and Markus, 1979), they can probably affect most other types of opinions as well.

### Conceptualizing and measuring elite discourse

The political information carried in elite discourse is, as we have seen, never pure. It is, rather, an attempt by various types of elite actors to create a depiction of reality that is sufficiently simple and vivid that ordinary people can grasp it. This "information" is genuinely information in the sense that it consists of what may be assumed to be sincere attempts to capture what is most important about what is happening in the world and to convey it in its proper perspective. But it is never "just information," because it is unavoidably selective and unavoidably enmeshed in stereotypical frames of reference that highlight only a portion of what is going on. In consequence, the public opinion that exists on a given issue can rarely be considered a straightforward response to "the facts" of a situation. Even topics that are within the direct experience of some citizens, such as poverty, homosexuality, and racial inequality, are susceptible to widely different understandings, depending on how facts about them are framed or stereotyped, and on which partisan elites are associated with which positions. In view of this, it is difficult to disagree with Lippmann's observation that while the orthodox theory holds that public opinion constitutes a moral judgment of a group of facts ... [it is more reasonable to hold that] . . . public opinion is primarily a moralized and codified version of the facts (1922/1946: p. 93). Thus, when I refer in the course of this book to the 'information carried in elite discourse about politics," as I often will, I will be referring to the stereotypes, frames of reference, and elite leadership cues that enable citizens to form conceptions of and, more importantly, opinions about events that are beyond their full personal understanding. The aim of the book is to show how variations in this elite discourse affect both the direction and organization of mass opinion. This conception of elite discourse, however, is more elaborate than can be fully measured and tested in this book. I have sketched it in order to indicate the larger picture into which my argument fits, and to acknowledge that elite discourse is a more complex phenomenon than my simple measures will make it out to be. For my measures really are quite simple and concrete. Often, I will make only a dichotomous measurement - whether there is a monolithic elite point of view on what a given issue is and how it should be handled, or whether there are important elite disagreements over the issue (see especially Chapter 6). In a few other cases, I will determine the relative intensity of opposing elite communications and how relative intensity changes over time. In these cases, I will be counting the number of media reports on a given issue, and the direction in which each report would tend to push opinion. Yet, as much research has shown, even simple story counts are sufficient to show a close relationship between elite discourse and mass opinion (Erbring, Goldenberg, and Miller, 1980; MacKuen, 1984; Page, Shapiro, and Dempsey, 1987; Fan, 1988; Page and Shapiro, in press; Brody, 1991). And, as the reader will see, they suffice equally well for the purposes of this book. By way of illustration, let me briefly describe changes in news reports on the issue of U.S. defense spending in the late 1970s and early 1980s, along with the associated changes in public opinion that they appear to have produced. On the cover of the October 27, 1980, issue of Newsweek was the headline,' 'Is America strong enough?" The inside story began as follows: Seldom in time of peace has the United States been so troubled by talk of war — and so much concerned that the country is incapable of waging it. The Army Chief of Staff, General Edward C. Meyer, complains publicly that he presides over a ''hollow army," undermanned, undertrained, and underfunded. General Lew Allen, the Air Force Chief of Staff, warns that his planes lack the spare parts necessary to command the skies in any sustained fight. The Chief of Naval Operations, Admiral Thomas B. Hayward, protests that he has a three-ocean mission and a ' 'one-and-a-half ocean Navy." And for the first time since the missile-gap scare of the 1960 presidential campaign, a feeling is building that American defenses have slipped - so badly that the nation may no longer be capable of protecting its interests abroad, or containing Soviet expansionism.
After what the magazine bluntly characterizes as inadequate responses to this situation by President Jimmy Carter and Ronald Reagan, his Republican opponent in the fall election, the story continues: There is little question that America's defense posture is not what it could be - or should be. Much of the military's equipment has aged to the point of obsolescence - and even the critical Minutemen ICBM's and B-52 bombers need continuing and expensive maintenance to stay competitive. Skyrocketing operating costs have ravaged the services and hamstrung their training efforts. Low pay scales and increasingly long stretches of sea duty for sailors and overseas tours for soldiers and airmen have prompted a mass exodus of the experienced noncoms who are at the heart of any fighting force. These problems all raise legitimate questions about the ability of the U.S. military to react to crisis and perform in combat. Stories of this type were not unusual in the late 1970s and early 1980s. By my count, in the 24 months prior to the 1980 election, Newsweek carried 57 stories that bore more or less directly on defense spending, 46 of which wholly or predominantly favored greater spending. A pro-spending posture was not, however, a permanent feature of Newsweek coverage of defense issues. As the new Reagan administration began to increase the level of defense spending, elite discussions of the issue - most notably in the form of objections by many congressional representatives that defense spending was squeezing out social spending - changed dramatically, and as this occurred, Newsweek coverage of the issue assumed a radically different character. Now the magazine filled its columns with information about multimillion dollar cost overruns, $600 air force screwdrivers, and other indications of Pentagon mismanagement. Instead of images of a decrepit U.S. fighting force, the public was given pictures of a bloated and wasteful military. Thus, in the 24 months following the 1980 election, there were 60 stories on defense spending, 40 of which assumed a posture opposed to defense spending. So, over a short period of time, coverage swung from about four-to-one in favor of greater defense spending, to two-to-one in favor of reduced expenditures. Public opinion on defense spending moved in tandem with these shifts in media coverage. At the end of the Vietnam War, most Americans wanted to cut defense spending, and as late as 1975, only about 10 percent felt too little money was being spent on defense. But, in response to a steady stream of prodefense images of the type just described, support for such spending rose steadily in the late 1970s, so that by early 1981, a slight majority of Americans felt that "too little" was being spent on defense. Then, as the news media began carrying a preponderance of information against defense spending, support for greater spending fell by more than 30 percentage points within a single year, leaving public opinion lopsidedly against increased defense spending. Such changes in public opinion, linked to clear shifts in the information carried in elite discourse, are a central topic of analysis of this book, especially the latter half of it. This section has suggested why and how elite discourse affects mass opinion. The next section will consider more carefully which members of the public are most susceptible to elite influence.

## MASS ATTENTION TO ELITE DISCOURSE

Although most Americans are, to use Downs's (1957) apt phrase, rationally ignorant about politics, they differ greatly in the degree of their ignorance. There is a small but important minority of the public that pays great attention to politics and is well informed about it. Members of this minority can recognize important U.S. senators on sight, accurately recount each day's leading news stories, and keep track of the major events in Washington and other world capitals. They are, thus, heavily exposed to elite discourse about politics. Any attempt to gauge the absolute size of this highly informed minority is essentially arbitrary (though see Bennett, 1989; Smith, 1989; Delli Carpini and Keeter, in press). Nonetheless, one indication of size is that when respondents to a National Election Study were asked to name as many members of the U.S. Supreme Court as they could remember, about 1.9 percent of the public could mention as many as half of the members, and a disproportionate number of those who could do so were lawyers or educators.5 Few Americans, it appears, are deeply familiar with the operation of their government. (By way of comparison, it is interesting to speculate what percentage of adults can name five or more starters on their city's major league baseball team; almost certainly, the figure is above 1.9 percent.) At the other end of the attentiveness spectrum is a larger group of people who possess almost no current information about politics. In late 1986, for example, when George Bush was halfway into his second term as vice-president of the United States, 24 percent of the general public either failed to recognize his name or could not say what office he held.6 People at this level of inattentiveness can have only the haziest idea of the policy alternatives about which pollsters regularly ask them to state opinions, and such ideas as they do have must often be relatively innocent of the effects of exposure to elite discourse. Most citizens, of course, fall between these extremes.7 Probably from some combination of civic obligation and the entertainment value of politics, a majority pays enough attention to public affairs to learn something about it. But even so, it is easy to underestimate how little typical Americans know about even the most prominent political events - and also how quickly they forget what for a time they do understand. For example, in the spring of 1989, the speaker of the House of Representatives, James Wright, resigned the speaker-ship amid allegations of scandal, the first time in American history that this had happened. The story was heavily covered in the media over a period of several months. Yet when, about three weeks after Wright's resignation, a national sample was asked about his resignation, only 45 percent could supply any reason for the resignation - even so much as a bare mention of scandal or wrongdoing. Or to take one other example: In the early summer of 1989, the U.S. Supreme Court announced a major decision on women's right to abortion, Webster v. Reproductive Services. Because pro- and antiabortion activists held large-scale demonstrations in an attempt to lobby the Court, there was extensive news coverage of the impending decision in the weeks before it was taken, and very heavy coverage when the decision was finally announced. Yet, in a survey done just after the decision, only about 50 percent of the public could say anything at all about how the Court had ruled, and, as the survey continued over the next several weeks, this percentage fell gradually to about 35 percent (Zaller and Price, 1990). Those who did learn about the abortion decision were obviously not a random 50 percent of the population: Citizens who paid regular attention to politics were far more likely to learn about the abortion decision than those who didn't. Figure 2.2 makes this point. Respondents to the survey were rated according to their general background levels of "political awareness." Persons scored high on political awareness if they were able to correctly answer a variety of simple factual information tests (such as which political party controls the House of Representatives), whereas persons scored low on awareness if they could answer none of these questions. As can be seen in the figure, almost all of the most highly informed persons - upward of 95 percent of those interviewed within the first three days of the Court's decision - could, when asked, supply the rudiments of the Court's ruling in the abortion case; but almost none of the persons at the low end of the awareness spectrum had absorbed any information about the decision. Data such as these on differential attentiveness to political news have immense implications for the impact of elite discourse on mass opinion, and taking systematic account of them will be a central task of this book. Figure 2.2 also shows that the people most strongly committed to women's right to abortion - in particular, the minority who said women should have an absolute right to decide for themselves whether to get abortions - were more likely to find out about the court decision than other persons. Yet their informational advantage was rather modest. There was, moreover, no difference at all between men and women in awareness of the decision. Even women of childbearing age did not differ from the rest of the public in their awareness of this issue (Price and Zaller, 1990). I mention this in order to give pause to readers who may suspect that, although citizens are often poorly informed about politics in general, they still manage to learn about matters that are especially important to them. Although there is some tendency for this to occur, as emphasized in Converse (1964), Iyengar (1990), Delli Carpini and Keeter (1990), McGraw and Pinney (1990), and some other studies, the tendency appears not to be very great or very widespread (Price and Zaller, 1990). The two main points about political awareness, then, are (1) that people vary greatly in their general attentiveness to politics, regardless of particular issues; and (2) that average overall levels of information are quite low. More succinctly, there is high variance in political awareness around a generally low mean. These points are widely familiar to professional students of public opinion (Converse, 1975; Kinder and Sears, 1985; Luskin, 1987; Bennett, 1989). Yet familiarity is often as far as it goes. Most of the time, when scholars attempt to explain public opinion and voting behavior, they build models that implicitly assume all citizens to be adequately and about equally informed about politics, and hence to differ mainly in their preferences and interests. In other words, they build models that ignore the effects of political awareness.8 One aim of this book is to provide a corrective for this dominant research practice. It may be useful to give an example of why a corrective is needed. The example concerns the effects of campaigns on voting behavior in congressional elections, but the issues it raises parallel those concerning the effect of elite discourse on public opinion generally. One of the most heavily researched problems in the congressional elections literature in recent years has been the advantage enjoyed by incumbents in the House of Representatives in their reelection bids. The average winning margin has increased dramatically in the past three decades, with the result that most House seats appear safe for the incumbent. House members have been able, by dint of their own efforts, to build a "personal vote" that is loyal to them regardless of partisan considerations. Thus it sometimes happens that a seat will be safe for a particular incumbent for a decade or more, but that when the incumbent retires, the seat will quickly become safe for a person of the opposite party. This development has given House members an independent standing that is almost unique among legislators in Western democracies and that seems to have vitally affected the performance of the American Congress (Cain, Ferejohn, and Fiorina, 1987; Jacobson, 1991). The reason for the rise of the personal vote, however, remains somewhat unclear. Less than half of the eligible electorate can recall the name of their congressional representative, and this figure has not changed in the period in which incumbents have become safer. But although most people cannot recall their incumbent's name, about 80 percent can recognize it. This discovery has become the basis for a claim that much of an incumbent's advantage occurs in the voting booth where voters are asked only to recognize rather than to recall who is serving as their member of Congress (Mann and Wolfinger, 1980). The typical congressional election, thus, takes place in a low-information environment in which a few people know the name of the incumbent and perhaps something about his or her record; many others can, with a prompt, recognize the incumbent's name and perhaps hazily recall one or two facts about the person's record or background; and still others know nothing at all about the incumbent. These differences in political awareness greatly affect the capacity of incumbents to develop a "personal vote" among their constituents - and yet they are typically ignored in research on the subject. In consequence, the dynamics of the personal vote have remained murky. To preview arguments that are more fully developed in Chapter 10, the people who know most about politics in general are also most heavily exposed to the incumbent's self-promotional efforts. Yet, as political sophisticates, they are also better able to evaluate and critically scrutinize the new information they encounter. So in the end, highly aware persons tend to be little affected by incumbent campaigns. If they share the party and values of the incumbent, they will support the incumbent whether he or she campaigns vigorously or not; if they do not share the incumbent's values, they will refuse to support him or her no matter how hard he campaigns. Meanwhile, at the low end of the awareness spectrum, those who pay little attention to politics tend to get little or no information about congressional politics. Hence they are also relatively unaffected by the efforts of the incumbent to build a personal following. This leaves the moderately aware most susceptible to influence: They pay enough attention to be exposed to the blandishments of the incumbent but lack the resources to resist. Evidence on this point is shown in Figure 2.3, which depicts the relationship between political awareness and the chances that people will desert their own party to vote for an incumbent member of Congress rather than their own party's candidate. The data involve contested seats in the 1978 general election. As can be seen, defection rates to the incumbent are markedly higher among moderately aware persons than among persons at the extremes of either high or low awareness.9 Note that if, as some researchers have done, one checks for a linear relationship in these data, one will discover little of interest. Awareness has strong effects, but its relationship with vote defection is nonmonotonic. (A relationship is said to be nonmonotonic when the association between variables is positive over part of the range of the independent variable and negative over the other part, as in Figure 2.3.) What is true of congressional elections is true of numerous other cases: Political awareness has important effects on many aspects of public opinion and voting behavior, but these effects are often strongly nonlinear. This makes them difficult to detect and model. Nonlinearity is, however, far from the only complication in detecting the effects of political awareness. In the example just discussed, we were concerned with the effects of a single political campaign, that of the congressional incumbent. Obviously, this is a highly simplified account of electoral politics. In most congressional elections, there are two main campaigns, each having some capacity to reach and mobilize sympathetic persons (though that of the incumbent nearly always has more). The same holds true in other mass persuasion situations. Public opinion is sometimes formed by streams of a monolithically one-sided elite discourse, but, more often, it is shaped by multiple and typically conflicting information flows, some of which are more intense, or easier to learn about, than others. Under-standing the effects of elite discourse on preference formation requires modeling the effects of awareness in mediating exposure to each of the major campaign messages in the environment, a task that presents serious complications. A final complication, as has already been suggested, is that opinion formation is a multistage process, and awareness may affect different parts of the process differently: Political awareness is associated with increased exposure to current communications that might change one's opinion, but it is also associated with heightened capacity to react critically to new information. These two effects may be cross cutting, as in the case of congressional elections, where the most aware persons are most heavily exposed to the incumbent's campaign but also most resistant. But this needn't be the case. There are, as we shall see, cases in which the most aware persons are the easiest segment of the public to reach and persuade, and other cases in which very inattentive persons are most susceptible to persuasion. Systematically explaining these and other ways in which political awareness affects public opinion and voting behavior will be the most important single contribution of this book.
In view of the central importance of political awareness, it is worthwhile to digress briefly to consider how best to conceptualize and measure it. Political awareness, as used in this study, refers to the extent to which an individual pays attention to politics and understands what he or she has encountered. Attention alone is not enough, since people who, for example, watch the TV news while lying on the couch after dinner and a couple of glasses of wine will typically fail to enhance their political awareness. The key to political awareness, then, is the absorption of political communications. Political awareness denotes intellectual or cognitive engagement with public affairs as against emotional or affective engagement or no engagement at all. Scholars have used a wide variety of concepts and measures to capture what is here being called political awareness. The concepts in the research literature include political expertise, cognitive complexity, political involvement, attentiveness, sophistication, and political acuity. Although choice of labels is perhaps mainly a matter of personal or disciplinary taste, my reason for preferring political awareness is that this term, better than the others, seems to capture the key processes in the model to be introduced here, namely an individual's reception and comprehension of communications from the political environment. Scholars have also used several different types of questions to operationalize what I am calling political awareness. These include media exposure, political participation, education, and self-described interest in politics. As I argue in the Measurement Appendix, political awareness is, for both theoretical and empirical reasons, best measured by simple tests of neutral factual information about politics. The reason, in brief, is that tests of political information, more directly than any of the alternative measures, capture what has actually gotten into people's minds, which, in turn, is critical for intellectual engagement with politics. Typical information questions, as suggested earlier, ask which political party controls the House of Representatives, or whether Mainland China is a member of the United Nations. Thus the information tests used to assess political awareness in this book are strictly neutral or factual. This point is stressed because, as indicated earlier, much of the information carried in elite discourse is neither neutral nor strictly factual. A news report implying that the Pentagon is awash in scandal and mismanagement, or a presidential remark to the effect that most unemployed persons could get jobs if they tried hard enough, constitute factual information in that they may contain some simple facts, and that they convey sincerely held beliefs about factual states of affairs. Yet they are not neutral, since they have been framed for partisan purposes and can be reasonably disputed by fairminded people. Some kinds of assertions, such as the claim that the spread of abortion signifies a degradation of American morals, are not even fully susceptible to empirical verification; yet the broadcast of this claim in the media would constitute a broadcast of information, since it would involve an assertion about the actual state of the nation. Nonneutral and not necessarily factual information, thus, is indistinguishable from political argumentation. Neutral factual information, such as which party controls Congress, is important in this book insofar as it measures a person's likely level of exposure to this other, nonneutral and not exclusively factual information. To avoid confusion between information of the neutral and nonneutral types, I will from this point onward use information exclusively in its nonneutral sense, as in ' 'information about the deterioration of American morals." Instead of referring to tests of neutral factual information, as used in measuring political awareness, I will simply refer to tests of political awareness or political knowledge. In order to remind the reader that information is normally used in its nonneutral sense, I will occasionally place the term in quotes. Also, for aesthetic reasons, I will sometimes substitute cognates of attentiveness for awareness, as in "politically inattentive" for "politically unaware."


## POLITICAL PREDISPOSITIONS

Citizens differ greatly in their levels of exposure to elite discourse, but these exposure differences can, by themselves, explain only a part of the variance in individual opinions. For citizens are more than passive receivers of whatever media communications they encounter. They possess a variety of interests, values, and experiences that may greatly affect their willingness to accept - or alternatively, their resolve to resist - persuasive influences. In this book, I refer to all of these factors as political predispositions, by which I mean stable, individual-level traits that regulate the acceptance or nonacceptance of the political communications the person receives. Because the totality of the communications that one accepts determines one's opinions (by means that I will specify), predispositions are the critical intervening variable between the communications people encounter in the mass media, on one side, and their statements of political preferences, on the other. The sources of variability in individuals' political predispositions are beyond the scope of this book. My assumption, however, is that predispositions are at least in part a distillation of a person's lifetime experiences, including childhood socialization and direct involvement with the raw ingredients of policy issues, such as earning a living, paying taxes, racial discrimination, and so forth. Predispositions also partly depend on social and economic location and, probably at least as strongly, on inherited or acquired personality factors and tastes.10 Since this book emphasizes the role of elite-supplied information in shaping mass opinions, I wish to stress that elites are not assumed to have an important role in shaping individuals' political predispositions. In my argument, predispositions mediate people's responses to elite information in the manner just indicated, but predispositions are not in the short run influenced by elites. It is likely that, over the long run, the elite ideas that one internalizes have some effect on one's values and other predispositions. But however this may be, this book is a study of opinion formation and change in particular short-term situations, and for this purpose, the long-term influence of elites on predispositions, to the extent that it exists, may be safely neglected.11 Of the various different types of predispositions, political values will receive the most sustained attention in this book. This is because they seem to have a stronger and more pervasive effect on mass opinions than any of the other predispositional factors.12 But some of the other factors, especially race and party attachment, are also very important and will receive significant attention. Values refer to "general and enduring standards" that hold a "more central position than attitudes" in individuals' belief systems (Kinder and Sears, 1985: p. 674) and that "lead us to take particular positions on social issues" (Rokeach, 1973: p. 13). Thus, for example, a person strongly attached to the value of economic individualism would, all else equal, be more likely to reject an argument for higher taxes to pay for social welfare spending than would someone less attached to this value. Political values, understood in this way, have recently become objects of serious scholarly study (for a review, see Kinder and Sears, 1985). Although this research has been quite useful in invigorating a previously moribund debate on the structure of mass opinions, it appears to have two important weaknesses. One of these weaknesses will be centrally addressed in this book, but the second must be provisionally resolved by assumption. The first limitation is that, like most public opinion research, the current literature on values largely fails to take systematic account of the vast differences in political awareness that exist among citizens. This failure is unfortunate because a frequent claim of the values literature has been that citizens who are, as most scholars agree, too unsophisticated to possess ''ideologies" nonetheless possess sufficient awareness to make reliable use of ''values" to structure their policy preferences. Thus, in a leading example of this research, Hurwitz and Peffley (1987) propose a hierarchical model of foreign policy opinions in which "core values" determine individuals' "general postures," which in turn determine opinions on particular foreign policy issues. The fact that many Americans are quite ignorant of foreign affairs is, according to Hurwitz and Peffley, precisely the reason that individuals must often fall back on core values and general postures to instruct their policy preferences: we see individuals as attempting to cope with an extraordinarily confusing world ... by structuring views about specific foreign policies according to their more general and abstract beliefs, (p. 1114) Although this point is an excellent one, citizens must still possess some minimal degree of information in order to recognize the relevance of their values for a given issue, and, as I have been arguing, it is quite easy to underestimate how often even minimal political information may be absent for some citizens. By way of illustration, we may examine opinions toward the U.S. policy of aid to the Contra rebels in Nicaragua. Figure 2.4 shows how citizens who differed in both their political awareness and in their predisposition toward use of military force responded in 1987 to a question on this topic. The persons classified as "hawks" in the figure are ones who said, over a set of general questions, that they strongly value military strength, an aggressive posture toward potential adversaries, and uncompromising opposition to communism. "Doves" are persons who rejected these positions, preferring to emphasize negotiations and accommodation with communism. Political awareness in the figure is measured by simple tests of factual knowledge about politics. (Items used in scale construction may be found in the Measures Appendix.) The left side of the figure shows that politically aware hawks and doves differ greatly on the question of whether U.S. "aid to the Contras in Nicaragua" should be increased, decreased, or kept the same: Forty-two percent of the most aware hawks, but only 3 percent of the most aware doves, favored increased Contra aid. However, among persons in the middle third of the awareness scale, hawks and doves differed only modestly, and among persons at the bottom of the scale, there were no value-based differences at all - a result that raises doubts whether the hawk-dove value dimension has any utility for understanding the views of poorly informed persons. However, the right-hand side of Figure 2.4 supports the conventional view of the importance of values. It shows responses to a question about whether the United States should send troops "to stop the spread of communism" in Central America. Here we find sharp differences between hawks and doves at all levels of awareness. Why the difference in response pattern to the two items, especially among less politically aware persons? The likely explanation is the contextual information carried in the two questions: The first, although scarcely lacking in clarity, requires respondents to know who the Contras are and what they stand for. This requirement will often go unmet among persons who are, in general, poorly informed about politics. (Commercial surveys taken in 1985 indicated that only about half of the American public knew which side the United States was supporting in the fighting in Nicaragua.) The second question in Figure 2.4, by mentioning communism, makes clear what the value implications of the issue are, thereby enabling people inclined toward hawkish foreign policies to recognize and support them. Thus, the impact of people's value predispositions always depends on whether citizens possess the contextual information needed to translate their values into support for particular policies or candidates, and the possession of such information can, as shown earlier, never be taken for granted. This contingency in the relationship between values and support for particular policies or candidates underlies this entire study, whose purpose, as I have indicated, is to show how individuals use information from the political environment to translate their values and other predispositions into more specific opinion statements. A second shortcoming of the values literature arises from its failure, so far, to specify the nature of the theoretical relationship of different value continua to one another and to political ideology. The problem arises from the fact that, although there are numerous ' 'value dimensions" between which there is no obvious logical connection, many people nonetheless respond to different value dimensions as //"they were organized by a common left-right dimension. There is, in other words, a tendency for people to be fairly consistently "left" or "right" or "centrist" on such disparate value dimensions as economic individualism, opinions toward communists, tolerance of nonconformists, racial issues, sexual freedom, and religious authority. The correlations among these different value dimensions are never so strong as to suggest that there is one and only one basic value dimension, but they are always at least moderately strong, and among highly aware persons, the correlations are sometimes quite strong.13 And, of course, there are also moderately strong correlations between people's self-descriptions as liberal or conservative and their scores on the various values measures. What, then, is the nature of the relationship between "values," as examined in recent research, and "ideology," which an older generation of researchers took so seriously? In view of the empirical covariation among measures of the two concepts, the question seems an obvious and important one. Let "values" be defined, as they normally are, as domain-specific organizing principles, such as economic individualism, where each value dimension lends structure to public opinions within a particular domain. "Ideology" may then be defined as a more general left-right scheme capable of organizing a wide range of fairly disparate concerns, where the concerns being organized include various value or issue dimensions or both. These definitions closely link the two concepts without, as far as I can see, violating the conventional meaning of either term. There are, however, two significant novelties. First, the various value dimensions are no longer conceptually independent; rather, each is one among several correlated dimensions of a master concept, ideology. Second, ideology is no longer the strictly unidimensional concept that many discussions have considered it to be, but a constellation of related value dimensions. The dimensionality of ideology may be analogous, in a certain respect, to the dimensionality of human intelligence. As a large psychological literature has shown and as common experience confirms, it is mistaken to say that there is a single dimension of intelligence. Thus, we all know people who are better at some kinds of tasks than others - mathematical reasoning rather than verbal expression, to take the most obvious case. Yet it is rare to find someone who is very high on one dimension and very low on another - a brilliant writer who cannot do simple addition and multiplication, or a great mathematician who cannot also generate fluent written prose. A person who is extraordinarily high on one dimension of intelligence tends to be at least fairly high on others. A similar thing appears to be true for ideology. It is unusual to encounter a person who is very liberal on one dimension of ideology and extremely conservative on another.14 There is a tendency, which is clear but not overpowering, for people to stake out roughly comparable positions on a series of seemingly unrelated left-right value dimensions. There are two practical implications of this view for the measurement of predispositions in this study. First, one should, whenever possible, use appropriate domain-specific measures of political values, rather than a general measure of ideology, as the operational measure of citizens' predispositions to accept or reject the political communications they receive. The reason is that ideology, as the more general measure of people's left-right tendencies, is more likely to miss reactions to a particular issue than is an indicator that has been tailored to that issue. The second implication of this analysis is that, since values are, to a significant extent, organized by a person's general ideological orientation, one can, if necessary, use general or omnibus ideology measures to capture people's leftright tendencies. And often it is necessary. Much of this book focuses on cases of opinion change, but there are relatively few cases of mass opinion change that have been captured by high-quality, publicly available surveys. Hence I must make full use of what little good data on opinion change are available. In some of these datasets, there are excellent measures of political values that capture exactly the value dimensions that regulate the opinion change. But in other cases, a survey may have only a very general measure of value orientation, such as liberal-conservative self-identification, or measures of value orientations that are not particularly close to the opinion that is undergoing change. In cases of this kind, I develop the best measure of general left-right tendency that I can and go ahead, hoping that one such measure may be, in practice, almost as good as another. (The measures employed are always generally described in the text of the book and exactly described in the Measures Appendix.) The justification for this practice, beyond sheer necessity, is the notion that there is a general leftright organizing principle that runs through many different value dimensions. This practice is obviously a conservative one. To the extent that general measures of value orientation fail to capture a predisposition that is related to the opinion undergoing change, I will tend to get weak or nonexistent relationships with values. And indeed, some of the relationships I have found appear weaker than I believe they would be if stronger value measures were available. Finally, a note on terminology. At some points in this study I will describe individuals as ''liberal" or ''conservative." In so doing, I will never mean to imply that the people so designated are necessarily full-fledged, doctrinaire ideologues of the left or right. I will mean only that the people tend to be closer to the left or right pole of some particular value dimension, or closer to one or the other pole of the constellation of associated liberal-conservative values. Thus, rather than say that a person is high on a measure of equalitarianism or high on a measure of hawkishness, I may say that the person is liberal or conservative. But whichever term I use, the important point to remember is that, for purposes of this book, values and ideology have exactly the same theoretical status: They are indicators of predispositions to accept or reject particular political communications.

## WHAT IS AN OPINION?

John Mueller begins his study of War, Presidents, and Public Opinion (1973) with a series of caveats that ought to appear on the opening pages of every book on public opinion, but which rarely do. He writes: The interview situation is an odd social experience. The respondent, on his doorstep or in his living room, is barraged with a set of questions on a wide variety of subjects by a stranger, usually a rather well-educated woman over 30, who carefully notes each response on a sheet of paper. Few people are accustomed to having their every utterance faithfully recorded and many find the experience flattering. And, aware that their views are being preserved for the ages, they do not wish to appear unprepared at that moment. Under these circumstances it is not surprising to find respondents pontificating in a seemingly authoritative, if basically "truthful," manner on subjects about which they know nothing or to which they have never given any thought whatsoever. ... (p. 1) The consequences of asking uninformed people to state opinions on topics to which they have given little if any previous thought are quite predictable: Their opinion statements give every indication of being rough and superficial. The opinion statements vacillate randomly across repeated interviews of the same people (see Table 2.1; also see Converse, 1964; Achen, 1975; Dean and Moran, 1977; Erickson, 1979; Feldman, 1989; Zaller, 1990); entirely trivial changes in questionnaire construction, such as switching the order in which questions are asked or response options are listed, can easily produce 5 to 10 percentage point shifts in aggregate opinion, and occasionally double that (Schuman and Presser, 1981; Bishop, Oldendick, and Tuchfarber, 1984; Tourangeau et al., 1989); and different ways of phrasing questions regularly have large effects on measured levels of public support for an issue. For example, Rasinski (1989) reports that, over several surveys, 68 percent of Americans felt too little money was being spent on 4'halting the rising crime rate," but that only 55 percent felt too little was being spent on "law enforcement." Similarly, 68 percent felt that too little was being spent on "protecting social security," but only 53 percent felt this way about spending on "social security." Or, in another type of case, 45 percent of Americans would "not allow" a communist to give a speech, whereas only 20 percent of Americans would "forbid" the same behavior (Schuman and Presser, 1981: p. 277). A record instance of the effects of changes in question wording may be a New York Times poll in 1983 which found that public support for a "freeze" on nuclear weapons production, at that moment a topic of heated interest, varied between 18 percent and 83 percent, depending on how the issue was framed.15 It is easy to think of reasons why few analysts of public opinion follow Mueller's example in exhibiting this catalogue of horrors in their opening pages. The most obvious is that they fear being dismissed out of hand, losing their audience before any argument has been made, if they too candidly reveal the dubious nature of the data on which their study depends. But a more important reason, I believe, is that no one knows quite what to make of the multiple vagaries of mass opinion. Most analysts truly believe that public opinion is a more substantial entity than is indicated by the evidence just cited - and yet the gloomy indications are all too real. Being unable to square all the facts with what one believes is true, one simply puts aside the troubling evidence for the time being, leaving it to survey methodologists to work out, and writes about those aspects of public opinion one does understand. An obvious problem with this approach is that it conceals information from the reader. Another is that it relinquishes the opportunity of making realistic statements about how mass opinion, in all of its elusiveness, forms and changes. In view of these considerations, the present study will make no effort to hide or underplay the types of problems with opinion data that have just been described. Indeed, it will make a theory of why the problems exist an integral part of its analysis. The theory is more simplistic than I would like, but it will at least address the problems head on. This approach is a gamble. Placing at the center of the book a theory of the nature of public opinion - a subject that neither I nor anyone else fully understands - ties its entire argument to some weak reeds, giving critics an opportunity to complain, correctly, that its foundations are uncertain. Whether the returns on this risky strategy, the opportunity to sketch a unified and realistic treatment of the dynamics of public opinion, have been worth their cost will be up to the reader to decide. Let me begin this part of my argument by recounting in more detail the vagaries of mass political opinion to which I have alluded; the relatively narrowgauge theories by which scholars have sought to explain some of these phenomena; and the more general theory that I will use to explain these findings and to integrate them into a model of the effect of elite discourse on mass opinions.

### Problems with mass opinion reports: Over time instability

Table 2.1 gives two typical examples of response instability over time. The first question, from a sample of respondents who were interviewed in January and again in June of 1980, asks whether the United States should try harder to cooperate with the Soviet Union, our Cold War adversary, or whether we should get tougher. As can be seen, 60 percent of those who favored a tougher stand in January still took this position in June; the rest were scattered across the other three options (greater cooperation with Russia, a middle position, or "no opinion"). Of those who took a neutral middle position in January, only 24 percent still did so in June, with most of the rest now favoring either more cooperation or less. Altogether, only 50 percent of the respondents took the same position in June that they had taken in January. (If everyone were simply guessing each time he were asked the question, roughly 32 percent would be expected by chance alone to state the same opinion on successive interviews, given my recoding of the item.) The same tendencies are apparent in the second question, which concerns the proper level of government services. Here, some 55 percent of the survey respondents managed to state the same opinion on successive interviews. One obvious interpretation of these flip-flops is that many people undergo genuine opinion change between interviews. The evidence, however, fails to support this interpretation. When the same respondents are asked the same question on three different occasions, one can typically predict their opinion on the third interview as well from the first interview as the second. If changes between the first and second interviews represented systematic opinion change, this would not be possible. The generally accepted conclusion, therefore, has been that response instability of the type shown in Table 2.1 predominantly represents some sort of chance variation. But what sort of chance variation, and why so much of it? In his famous paper on "The nature of belief systems in mass publics," Converse (1964) argued that opinion instability is due mainly to individuals who lack strong feelings on the given issue but nevertheless indulge interviewers by politely choosing as best they can between the response options put in front of them - but often choosing in an essentially random fashion. "[L]arge portions of an electorate," he suggested, "simply do not have meaningful beliefs, even on issues that have formed the basis for intense political controversy among elites for substantial periods of time" (1964: p. 245). This conclusion has been strongly challenged by scholars who contend that, although people's "survey responses" fluctuate greatly, citizens have underlying "true attitudes" that are overwhelmingly stable (Achen, 1975, 1983; Dean and Moran, 1977; Erikson, 1979; Judd and Milburn, 1980; Judd, Milburn, and Krosnick, 1981; Feldman, 1989; Zaller, 1990; an exception is Krosnick, 1988; for general reviews, see Kinder and Sears, 1985 and Smith, 1984). The fluctuations that appear in people's overt opinion statements are attributed to "measurement error,'' where such error is said to stem from the inherent difficulty of mapping one's preexisting opinions onto the unavoidably vague language of survey questions. The theory of measurement error has an especially attractive implication. If one believes that attitudinal variables have been measured with large amounts of random error, it follows that their correlations with other variables will be artificially deflated. And if this is so, it is legitimate to reinflate these depressed correlations by means of standard psychometric techniques, which researchers routinely do. Thus, attitudinal variables which, in fact, exhibit high instability over time and low correlations with other variables are made, by means of correction procedures, to appear almost perfectly stable and highly correlated with other variables. In this way, the problem of response instability is rendered not only innocuous but invisible. Both the Converse and measurement error approaches to response instability appear to have deficiencies. Converse's thesis, which takes any instability as evidence of a "nonattitude," was an extreme claim intended to characterize opinions only on certain highly abstract issues. On more typical issues, as Converse and Markus (1979) argue, people's opinions may be more or less "crystallized" and are, as a result of this, more or less stable. But this only raises the question of what exactly crystallization consists of. Since no one has ever said, opinion crystallization remains more a metaphor than a testable theory of opinion stability (Krosnick and Schuman, 1988). The newer "measurement error" theory of response instability seems equally underspecified at its theoretical core. When, as all estimates agree, measurement ' 'error'' normally constitutes one-half to three-quarters of the variance of opinion items, one naturally wonders what this chance 'error" consists of and how it has been generated. Yet researchers have been remarkably uncurious about this problem. In a large majority of cases in which it is acknowledged, analysts make a statistical correction for it and move quickly on to whatever their study is mainly about. As a result, "measurement error" is closer to being a euphemism for "unexplained variance" than it is to being a wellunderstood phenomenon (see, however, Schuman and Presser, 1981; Krosnick and Berent, 1992).

### Problems with mass opinion reports: "Response effects"

A second embarrassment to the conventional view of opinions has been the discovery of substantial amounts of nonrandom or "systematic error" in people's opinion reports. Many respondents react to the context in which a question is asked, to the order in which alternative responses are presented, and to wholly nonsubstantive and trivial alterations in questions. The systematic effects of such seemingly irrelevant features of the interview process are known as "response effects." Consider a well-known experiment during the 1970s on Americans' opinions toward Soviet journalists. In a split-half sample, 37 percent of respondents were willing to allow Communist reporters in the United States. Yet when, in the other half-sample, respondents were first asked whether U.S. reporters should be allowed in Russia (which most favored), the percentage agreeing to allow Russian reporters into the United States nearly doubled to 73 percent. The explanation for this huge difference, as Schuman and Presser (1981) suggest, is that when people are asked the Communist reporters item alone, they respond on the basis of anti-Communist opinions. When, however, the question is preceded by one about American reporters working in Russia, a norm of reciprocity is immediately made salient and a substantial number of respondents feel bound to provide an answer that is consistent with their previous response. . . . The crux of the matter seems to be that the reporter questions have two meanings, one involving an attitude toward an object and another involving an attitude toward a norm, (p. 28) Note that this explanation implicitly abandons the notion that individuals possess a single, fixed opinion toward the rights of Communist reporters. Rather, individuals are assumed to have at least two considerations, one involving Communists and the other involving the norm of fair play, and to answer the question according to whichever consideration has been made salient by the questionnaire. There are numerous other findings of this type: People are less likely to describe themselves as interested in politics just after they have been asked about obscure issues (Bishop et al., 1984); people's opinions toward abortion are affected by the kinds of items (concerning, for example, religion or women's rights) that precede it (Tourangeau and Rasinski, 1988; Tourangeau et al. 1989); people give quite different answers to open-ended questions than to questions that ask them to choose among a series of prespecified options (Schuman and Scott, 1987).

### Question-wording effects

It is uncommon for a change in question order to shift public opinion by more than 10 or 15 percentage points, and many shift opinion by smaller amounts or not at all. Changes in the substantive wording of questions can, on the other hand, produce much larger effects on political opinions and can do so much more reliably. Yet these changes are not normally considered either worrisome or even especially interesting. The feeling seems to be that differently worded questions should get different answers, since they change either the emotional loading of the issue or, in some cases, what the respondent is being asked about. It is not clear, however, that this complaisance is warranted. It is, for example, well established that adding the endorsement of a prominent politician to a policy question - as in, "Do you favor or oppose President X's policy of . . . ?" is likely to change the public's response to that issue, depending on the popular view of President X. But if, as conventional opinion models assume, citizens have preexisting "true attitudes" that they merely reveal to the inquiring pollster, such "endorsement effects" should not occur. The fact that they do occur, and quite reliably, indicates that many respondents are making up their opinions - or at least editing and modifying them - as they go through the questionnaire. Consider another type of question wording effect. In his study of support for the Korean War, Mueller (1973) found that people were more likely to express support for the war if the antiwar option required them to confess that their country had made a mistake by entering the war. Similarly, support for the war was consistently 15 to 20 percentage points greater if the war was described as necessary to stop communism. When both factors were at work, their joint impact on opinion was considerable. Thus, in one poll taken in the fall of 1953, only about 38 percent of the public said that "the Korean War has been worth fighting"; but in another poll taken at about the same time, 64 percent said that the United States "did the right thing in sending troops to stop the Communist invasion" (Mueller: table 3.1). As Mueller remarked, These data suggest somewhat conflicting observations. On the one hand, support for the war was clearly tied to the anti-Communist spirit in America at the time. To generate a kind of war fever, one merely had to toss the words, "Communist invasion," into the discussion. On the other hand, the Communist element was not entirely built into the response to the war because Americans had to be reminded of it before their antiCommunism was fully activated. . . . (Mueller 1973, pp. 46-8) So, we again find out that a sizable fraction of survey respondents appear to form their opinions during the interview on the basis of the ideas made salient to them by the question, rather than simply revealing preexisting "true attitudes."
The counterargument to this conclusion - that different questions were involved and should therefore be expected to produce different answers even if people did have preexisting opinions - does not seem to me credible. The issue that people were addressing - the appropriateness of the U.S. response to an invasion of South Korea by the Communist government of North Korea - was the same whether or not the survey question used the critical phrase, "Communist invasion." Thus, anyone who had a fixed opinion on the war should have been able to express it whether communism was mentioned or not. A clear demonstration that changes in question wording can change people's responses even when the underlying issue remains exactly the same may be found in Tversky and Kahneman's (1982) case of the rare Asian disease. These two psychologists put the following questions to a sample of college students: Imagine the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows: If program A is adopted, 200 people will be saved. If program B is adopted, there is a one-third probability that 600 people will be saved, and a two-thirds probability that no people will be saved. Which of these two programs do you favor? This problem requires respondents to choose between a certain fixed loss and a gamble having an identical expected loss. In this case, 72 percent chose the certain loss, that is, saving 200 persons via program A. Yet when a comparable sample was asked in a differently worded question to respond to precisely the same dilemma, the results were radically different. In the second sample, the alternatives were described as follows: If program C is adopted, 400 people will die. If program D is adopted, there is a one-third probability that nobody will die, and a two-thirds probability that 600 people will die. In this situation, only 22 percent chose the certain loss of 400 lives - a reduction of 50 percentage points. The conclusion to be drawn from this example, as from earlier ones, is that differences in the wording of questions can determine how people think about and hence respond to issues even when, as here, the denotative meanings of the competing wordings are exactly the same.


### The need for a model of the survey response

There are, to reiterate, two types of evidence that weigh against the conventional notion that individuals have preexisting attitudes that they simply reveal in response to survey questions. The first is the widely replicated finding that 50 to 75 percent of the variance in typical opinion items is random "error" - an amount that is too large to be comfortably ascribed to the effects of vaguely worded questions. The second is the evidence of large amounts of systematic "error" arising from the effects of question order and question wording.
These findings are more than methodological curiosities. They seriously undermine the conventional view that surveys are passive measures of "what the public really believes.'' More ominously, they raise the fear that a large fraction of what opinion researchers measure is either random or systematic "noise." In the last fifteen years, survey methodologists and social psychologists have recognized this problem and sought to deal with it. They have tended to abandon the conventional notion that people possess fixed opinions that they simply reveal in surveys, and have begun to concentrate instead on the "questionanswering process" by which individuals construct opinion reports in response to the particular stimulus that confronts them. In a recent example of this research, Wilson and Hodges (1991) describe the traditional view of attitudes as being essentially a "file drawer" model of attitudes: When people are asked how they feel about something, such as legalized abortion, their Uncle Harry, or anchovies on a pizza, presumably they consult a mental file containing their evaluation. They look for the file marked ''abortion," or "Uncle Harry," or "anchovies," and report the evaluation it contains. But Wilson and Hodges (1991) reject the general validity of this model. "People often construct their attitudes, rather than simply reporting the contents of a mental file." Their attitude reports are based on the ideas in a large but internally conflicted "database," so that the "attitude" that is reported at a given time is a "temporary construction" which depends on peculiarities of the process by which a person has constructed it. Wilson and Hodges are not the only researchers to entertain such radical notions. In a prominent 1988 paper, Tourangeau and Rasinski also abandoned the traditional view of political attitudes and proposed to replace it with a general model of the "question-answering" process by which people construct attitude statements. (I will deal further with their model later on.) Similar though more modest steps have been taken by Schuman and Presser (1981), Bishop et al. (1984), Iyengar and Kinder (1987), Bartels (1988), Kinder and Sanders (1990), and Popkin (1991). Unfortunately, most research on the new "question-answering models" has tended to focus on response effects, and has had nothing to say about either random response instability or the larger process by which people form their opinions in response to information gleaned from the political environment. What is therefore needed is a broader question-answering model. This is what I attempt to provide in this book. Like a fair number of survey methodologists and psychologists, I abandon the conventional but implausible view that citizens typically possess "true attitudes" on every issue about which a pollster may happen to inquire, and instead propose a model of how individuals construct opinion reports in response to the particular stimuli that confront them. This model unites in one theory an account of how people acquire information about politics, as sketched in the first part of this chapter, with an account of how they use that information to formulate responses to typical survey items. The model is consistent with - indeed, it seeks to provide explanations for - the vagaries of the mass survey response, as outlined in these pages. The argument, first made in a 1984 convention paper (Zaller, 1984b), is roughly as follows: People are continuously exposed to a stream of political news and information, much of it valenced so as to push public opinion in one direction or the other. But, owing to the generally low levels of attention to politics in this country, most people on most issues are relatively uncritical about the ideas they internalize. In consequence, they fill up their minds with large stores of only partially consistent ideas, arguments, and considerations. When asked a survey question, they call to mind as many of these ideas as are immediately accessible in memory and use them to make choices among the options offered to them. But they make these choices in great haste - typically on the basis of the one or perhaps two considerations that happen to be at the "top of the head"16 at the moment of response. The basic claim of the model, thus, is that survey responses are a function of immediately accessible "considerations," where the flow of information in elite discourse determines which considerations are salient. The reason for response instability, on this view, is that different considerations happen to be salient at different times, which causes people's survey responses to differ over repeated interviews. Changes in question order or question wording can bring about systematic changes in the considerations immediately salient to people, and hence systematic changes in their survey responses. By way of illustrating the operation of the model, consider how typical citizens might have responded to a question about the proper level of U.S. defense spending during the cold war. Most would have heard a fair amount about the issue without ever having had the occasion to answer a survey question about it. They might have been upset about reports of Pentagon waste and mismanagement, but they might also have worried about the Soviet threat and America's capacity to contain it - all without thinking about or even recognizing the tradeoffs between these competing concerns. When unexpectedly asked on a survey for their opinion on defense spending, they must have, in just a second or two, somehow pulled these and other thoughts together into a "survey response" on defense spending. In doing so, they did not fully canvass their minds for all relevant thoughts. Rather, if they had happened the night before to see a news program on a major defense procurement scandal, they might answer the question on the basis of that consideration. But if, on the other hand, they had been reminded by an earlier question about the threat of Soviet aggression they might instead answer that defense spending should remain high. And if, in a follow-up survey sometime later, the survey questions were asked in a different order, or if they had seen a different TV program the night before, they might have had different ideas at the tops of their heads and hence made different survey responses. 16 
An important feature of the model is that people who are more politically aware are more selective about the "information" that they internalize - which is to say, they will be more likely to reject ideas that are inconsistent with their values. As a result of this selectivity, the ideas they internalize are more internally consistent and more consistent with their values. Responses to closedended survey questions reflect this by exhibiting greater over time stability and greater ideological consistency with one another.

### Background of the question-answering model

Although the suggestion of a question-answering approach to understanding mass opinions is still novel within the public opinion field, it is approaching the status of orthodoxy in some psychological circles. It is instructive to review some of the research on which this emerging orthodoxy rests. One strand of this research, conducted by mathematical psychologists and focusing on problem solving, regards the mind as a sort of bin filled with multiple interpretive constructs. Confronted with a set of "stimulus elements" (raw sensory impressions) in a problem, individuals stochastically search their minds for constructs that enable them to make sense of the stimuli (Atkinson, Bower, and Crothers, 1965). An interpretive construct, once chosen, determines one's understanding of the stimuli and hence one's response to it. A person's judgments, thus, depend quite directly on the ideas that happen to come to the top of the mind at critical points in the problem-solving exercise. Another research tradition, common among social psychologists and mainly concerned with social cognition, focuses on the organization of ideas in the mind. A central concept in this research is "schema," a term that has been adapted from cognitive psychology. A schema is a cognitive structure that organizes prior information and experience around a central value or idea, and guides the interpretation of new information and experience. A critical point about schemata is that people typically have several of them available for understanding any given phenomenon. For example, an individual being introduced to a "forty-year-old professor" would react quite differently if the same person were instead introduced as "a forty-year-old mother of three." That is, different associations would come to mind, different qualities of the person would be noticed, different conclusions would be drawn from the person's mannerisms, and so forth. In short, the perceiver's "attitude" toward the person would be different. Thus Tesser (1978), in statements that nicely capture a central feature of the model being suggested, writes: An attitude at a particular point in time is the result of a constructive process. . . . And, there is not a single attitude toward an object but, rather, any number of attitudes depending on the number of schemas available for thinking about the objects. [Pjersons do not have a single feeling or evaluation of an object. Feelings vary depending upon theparticular cognitive schema we "tune in." (pp. 297-8, 307, emphasis in the original) The key idea in these studies is that individuals do not typically possess "just one opinion" toward issues, but multiple potential opinions. The logical next question is then how, in the face of this, people manage to come to decisions at all. This turns out to be an immensely complicated issue, involving the encoding of incoming information, perception or interpretations of information, efficiency of memory search, and degree of motivation, among other things. Thus, psychologists attempting to come to grips with these various issues have proposed models that are fearfully complicated (e.g., Wyer and Srull, 1989). One point that does, however, appear reasonably clear is that, in the course of making decisions, including those involving political matters, individuals rarely take the time to canvass their minds for all relevant thoughts. Life is too short and the human mind too fallible. Rather, they appear to make decisions "off the top of the head" on the basis of whatever ideas are immediately accessible in memory. Thus, as Taylor and Fiske (1978) note, numerous studies have shown that the introduction or emphasis of a single piece of information - such as the fact that a particular person is a woman or a lawyer - can greatly affect subsequent expressions of opinion. Reviewing a variety of such evidence, Taylor and Fiske maintain, in an argument quite novel for its time, that many people make social judgments by seizing on a single, sufficient and salient explanation . . . often the first satisfactory one that comes along. . . . [I]nstead of employing base rate or consensus information logically, people are more often influenced by a single, colorful piece of case history evidence. ... Instead of reviewing all the evidence that bears upon a particular problem, people frequently use the information which is most salient or available to them, that is, that which is most easily brought to mind. (p. 251) On the basis of a much larger volume of evidence, Wyer and Srull (1989) maintain that people are unlikely to conduct an exhaustive search of memory for all of the knowledge they have accumulated that is relevant to a particular decision. Rather they retrieve and use only a small subset of this knowledge, apparently assuming that its implications are representative of all the knowledge they have acquired, (p. 81) Yet, at the same time, much data in political science (Kelley, 1983), political psychology (Lodge, McGraw, and Stroh, 1989), and cognitive psychology (Anderson, 1974) make it clear that individuals may often utilize many diverse pieces of information in their decision making. For example, Kelley (1983) shows that voters decide between presidential candidates as if they were summing up numerous "likes" and "dislikes" about each party and candidate and choosing the one with the highest net total. Anderson's information-averaging models, which have achieved wide recognition in psychology, likewise show that individuals make use of a wide set of relevant cognitions in formulating opinion statements. The model I propose tries to accommodate both top-of-the-head decision making, as suggested by Taylor and Fiske, and averaging across potentially large amounts of disparate information, as suggested by Kelley and by Anderson. It does so by assuming that individuals make decisions by averaging over a nonrandom but stochastic sample of relevant considerations, where the size of the sample of considerations may vary between 1 and large. The size and composition of this sample depend on a variety of contextual and individual motivational factors, such as what ideas have been made salient by the questionnaire and how much attention a person generally pays to the subject at hand. 

## SUMMARY

This study focuses on interactions among three broad classes of variables: Aggregate-level variation in the information carried in elite discourse, including elite cues about how new information should be evaluated, individual-level differences in attention to this discourse, and individual-level differences in political values. Interactions among these variables determine the mix of "considerations" that gets into people's heads. Which of these considerations is available at the top of the head at the moment of confronting survey questions determines responses to the questions. A model based on these ideas is presented in the next chapter.


# Chapter 3: How citizens acquire information and convert it into public opinion

- The comprehensive analysis of public opinion requires attention to two phenomena: how citizens learn about matters that are for the most part beyond their immediate experience, and how they convert the information they acquire into opinions. This chapter proposes a model of both phenomena. The model does not provide a fully accurate account of how people process information and form attitude statements. No model that is both parsimonious and testable on typical mass opinion data - the two most important constraints on my enterprise could possibly do so. But the proposed model, as I hope to persuade the reader, does a plausible job of approximating what must actually occur, and a quite excellent job of accounting for the available survey evidence across a wide range of phenomena. Having stated a model of the opinionation process in this chapter, I proceed in the rest of the book to test a series of propositions derived from the model. Some additional ideas will be needed to accomplish this, but they are few and incidental. All of the important features of my analysis derive from the model that is presented here.

## SOME DEFINITIONS

I begin the statement of the model with definitions of primitive terms. The first is consideration, which is defined as any reason that might induce an individual to decide a political issue one way or the other.1 Considerations, thus, are a compound of cognition and affect - that is, a belief concerning an object and an evaluation of the belief. "President Bush's plan to balance the federal budget is fair to all competing interests" is an example of a consideration that might impel an individual to say, in response to a survey question, that she approves of the way President Bush is handling his job as president. The cognitive element in this consideration is information about Bush's tax plan, and the affect is the favorable evaluation of it.2 Suppose that someone sees on the TV news the image of a "bum on the street," reacts with hostility, and makes this hostility the basis of an opinion statement opposing increased government spending on the homeless. It might initially seem that this hypothetical opinion statement is based on a purely affective response rather than a blend of cognition and affect. Yet a cognitive component is clearly present: The person on the street has been seen as a "bum" rather than "a person like myself who has unfortunately lost his job." Thus, the negative evaluation depends on a particular cognitive representation of what one has seen, which is to say, a combination of cognitive and affective elements. Although much more could be said about considerations, particularly their possible role in guiding perception, the concept in its present spare form suffices for a great many purposes, as will become apparent.3 Second, I define two types of political messages: persuasive messages and cueing messages. Persuasive messages are arguments or images providing a reason for taking a position or point of view; if accepted by an individual, they become considerations, as the term was just defined. A speech by a Democratic politician charging that "President Bush's budget plan is a sham and a delusion" is an example of a persuasive message. Note that there is nothing in this account that implies that either political messages or the considerations that result from them must be coldly rational. On the contrary, messages may involve subtle or even subliminal images, and considerations may involve feelings or emotions. Thus, a president may seek to project a "message" of competence in his public presentations, in the hope that it will make the public feel warm or secure. If the president is cognized in this way, and if this cognitive representation generates feelings of security that positively influence how citizens evaluate the president's job performance, the feelings of security must be counted as reasons for favorably evaluating the president - that is, as considerations. I wish to underscore these points because, although the model I propose has a cognitive flavor, it is, in principle, as capable of dealing with nonrational appeals and inarticulate feelings as with other kinds of political discourse.
Cueing messages, which are the second type of message carried in elite discourse, consist of "contextual information" about the ideological or partisan implications of a persuasive message. The importance of cueing messages is that, as suggested by Converse (1964), they enable citizens to perceive relationships between the persuasive messages they receive and their political predispositions, which in turn permits them to respond critically to the persuasive messages. Thus, a Republican voter will be more likely to reject criticism of President Bush's budget plan if she recognizes that the person making the criticism is a Democrat. We saw a clear illustration of the importance of cueing information in the last chapter, where politically unaware hawks and doves were unable to make a partisan response to a question about aid to the Contra guerrillas in Nicaragua because they apparently lacked contextual information about who the Contras were. These same hawks and doves could, however, respond in partisan fashion to a question about combating communism in Central America because communism was a cue they understood.

## THE MODEL

The model itself consists of four assertions, or axioms, about how individuals respond to political information they may encounter. Each is stated first as a general theoretical position and then elaborated and justified in more precise terms. As will become apparent, none of the axioms is individually original, nor can it be said that any of the four axioms is a perfect representation of what occurs in the world. I hope, however, to show that the axioms, taken as a group, have some highly novel and empirically correct implications, and also that, even though not perhaps perfectly true, the axioms are quite plausible approximations of the processes that must actually occur as individuals acquire information about politics and use it to formulate statements of their political preferences. A1. RECEPTION AXIOM. The greater a person s level of cognitive engagement with an issue, the more likely he or she is to be exposed to and comprehend - in a word, to receive -political messages concerning that issue.4 The messages people may receive include all types: that is, persuasive messages and cueing messages. In specifying the reception axiom in terms of cognitive engagement rather than, say, strength of feeling about an issue, the model obviously stresses the cognitive aspect of exposure to political communications. There are two reasons for this. The first is that, as indicated, the model is most centrally concerned with how individuals acquire information from the environment and convert it into opinion statements. These are essentially cognitive processes, so that affective engagement is likely to be able to affect them only insofar as it leads to intellectual - which is to say, cognitive - engagement. Hence it is appropriate to define the model in terms of cognitive engagement. The second reason is that, as an empirical matter, survey measures that capture cognitive engagement with politics outperform measures of affective engagement in explaining most aspects of public opinion. For example, people who score higher on tests of political knowledge are substantially more stable in their attitude reports than people who score low on political awareness (Feldman, 1989; Zaller, 1990); however, people who describe themselves as highly interested in politics, which I take as a form of affective involvement, are not significantly more stable than persons who express little political interest (Zaller, 1990: table 2). It is interesting to note that political interest, despite its limited effect on response stability, is a strong correlate of voter turnout - slightly stronger, in fact, than political knowledge (Zaller, 1990: table 1). So, affective engagement can be important, but unless coupled with intellectual engagement, it appears to have only limited effects on opinion per se. Although cognitive engagement is the right specification for my model, it is a cumbersome and somewhat precious phrase. Therefore, I will, through most of the analysis that follows, use a simpler phrase, namely political attentiveness or political awareness. But cognitive engagement, political attentiveness, and political awareness are meant to convey the same meaning. In the analysis that follows, political awareness is operationally measured mainly by means of a general measure of political knowledge - that is, a person's summary score across a series of neutral, factual tests of public affairs knowledge, as discussed in the previous chapter. Political awareness, measured in this way, is a measure of general, chronic awareness. As such, it does not directly test individuals' information about or attention to a particular issue at a particular time. In using this sort of measure, I will be assuming that persons who are knowledgeable about politics in general are habitually attentive to communications on most particular issues as well. This measurement strategy is less than ideal. More narrowly focused measures of awareness - devoted exclusively, say, to intellectual engagement with foreign policy issues or race policy issues, and used exclusively in connection with reception of information concerning foreign or race policy issues - would be preferable to general awareness measures. However, such domain-specific awareness measures are rarely carried on opinion surveys and none are available for the cases I examine in this study. As a practical matter, thus, I must make do with general measures. Yet, as far as I have been able to tell from investigation of similar problems, the loss from using general rather than domain-specific awareness measures to capture exposure to elite discourse is minimal (Zaller, 1986; Price and Zaller, 1990; though see also Iyengar, 1990; see Chapter 2 and the Measures Appendix for further discussion.) The reader should note that the Reception Axiom, Al, indicates nothing about the sources of the political communications that shape mass opinion. As far as that axiom is concerned, political communications may originate in elite discourse, in purely personal exchanges among friends and neighbors, or in other ways. All that is claimed in Al is that reception of politically relevant communications, whatever their origin, is positively associated with intellectual engagement with a given issue. By extension, political awareness is assumed to capture propensity for reception of political communications generally, regardless of their point of origin. It would obviously be desirable to be able to measure exposure to interpersonal influence independently of exposure to elite discourse in the mass media. However, it is not possible to do so from the available data. Some surveys do carry measures of people's self-reported frequency of personal discussion of politics, but there is, as with measures of political awareness, no guarantee that they would capture exposure to only one type of communication.5 Thus, the reader should bear in mind that the assumption that it is the information carried in elite discourse, rather than personal influence or something else, which shapes mass opinion is not a part of the formal model that I am laying out in this chapter. It is, rather, an auxiliary assumption that requires independent justification, as I have sought to provide in the first part of Chapter 2 and will provide in parts of the analysis reported below. I extensively discuss this point in my closing evaluation of the book's argument in Chapters 11 and 12. A2. RESISTANCE AXIOM. People tend to resist arguments that are inconsistent with their political predispositions, but they do so only to the extent that they possess the contextual information necessary to perceive a relationship between the message and their predispositions. The key to resistance, in this formulation, is information concerning the relationship between arguments and predispositions, where the requisite information is carried in cueing messages. According to the Reception Axiom, the probability of individuals acquiring cueing information depends on their levels of awareness of each given issue. Thus, Al and A2 together imply that the likelihood of resisting persuasive communications that are inconsistent with one's political predispositions rises with a person's level of political attentiveness. Or, to put it the other way, politically inattentive persons will often be unaware of the implications of the persuasive communications they encounter, and so often end up "mistakenly" accepting them. This postulate makes no allowance for citizens to think, reason, or deliberate about politics: If citizens are well informed, they react mechanically to political ideas on the basis of external cues about their partisan implications, and if they are too poorly informed to be aware of these cues, they tend to uncritically accept whatever ideas they encounter.6 As normatively unappealing as this implication of the model may be, it is consistent with a large body of theory and research concerning political persuasion. Philip Converse, the leading theorist of mass opinion, maintains that few people reason for themselves about how political ideas relate to one another. Rather, to the extent that individuals respond critically to the political ideas they encounter, they rely on contextual information from elites about how different ideas "go together" and thereby "constrain" one another (Converse, 1964). Although he does not say so, the contextual information that Converse describes would surely include the particular groups or leaders who favor or oppose an idea. A central point in Converse's analysis is that awareness of contextual information is likely to depend on general levels of political awareness. Hence, only people attaining fairly high levels of awareness are likely to respond to communications in a manner that is "constrained" by their values. The psychological literature on opinion change lends great support to the notion that individuals typically fail to reason for themselves about the persuasive communications they encounter. Instead, people rely on cues about the "source" of a message in deciding what to think of it. Reviewing this evidence in an influential 1969 article, William McGuire wrote: The given message is judged as fairer, more factual, more thoroughly documented, its conclusion following more validly from its premises, and even more grammatical, when it is ascribed to a high- as opposed to a low-credibility source, (p. 198) Although the studies McGuire cites do not necessarily involve political sources that are Democrat or Republican, or liberal or conservative, they ought to generalize to these kinds of sources (see, for example, Belknap and Campbell, 1951-2; Mueller, 1973; Price, 1989). McGuire goes on to note that people do not seem to learn more from credible sources; they simply tend to accept their opinion leadership more readily. This pattern, he continues, suggests again that the receiver can be regarded as a lazy organism who tries to master the message contents only when it is absolutely necessary to make a decision. When the purported source is clearly positively or negatively valenced, he uses this information as a cue to accept or reject the message's conclusions without really absorbing the arguments used. Recent research has sketched a somewhat more encouraging picture of the critical capabilities of the "receiver." For example, Rhine and Severance (1970) have found that college students pay no attention at all to credibility of the source when the topic of the message is one that engages their interest, which in this case was whether college tuition should be raised. Source effects, these researchers found, were limited to non-4'ego-involving" issues, such as how much land should be set aside for parks in a distant community. Most recently, the work of Chaiken (1980) and Petty and Cacioppo (1986) has provided clear support for the view that individuals will, under certain circumstances, entirely ignore such factors as ''source credibility" and instead base their attitudes on the quality of the persuasive information they have been given. A typical Petty and Cacioppo experiment runs like this: Underclass college students are presented with persuasive arguments on a topic of potentially great interest to them - whether senior comprehensive exams should be a requirement for graduation. This is an idea that, needless to say, undergraduates are predisposed to resist. Half the students are exposed to "strong" arguments for comprehensive exams, such as the example of a university that instituted such exams and then found that the starting salaries of its graduates rose $4,000 over a two-year period, and the argument that law schools give preference to students from schools having the senior exam requirement. The other half of the students are given "weak" arguments, such as the arguments that many colleges are considering the exams, so the school could be at the forefront of a national trend, and that graduate students, who must take comprehensive exams, feel it is only fair that undergraduates should have to take them too. In each of these conditions, half the students are told that the proposal is to institute the new requirement the following year, so that it would apply to them ("highinvolvement" condition) and half are told that the requirement is being considered for possible adoption in ten years ("low-involvement" condition). Finally, half the students are told that the source of the arguments they are getting is a Princeton professor (a "high-credibility" source) and half are told that the arguments have been taken from the report of a local high school class (a "lowcredibility" source). The experimental design, thus, is two message types x two involvement conditions x two source types. The results are as follows: Low-involvement students pay some attention to the quality of the arguments but are most strongly affected by the credibility of the sources advocating them; hence they are favorable toward comprehensive exams only when the source advocating them is a Princeton professor. Highinvolvement students, by contrast, pay no attention to source credentials, but are powerfully influenced by the strength of the arguments. Thus, they are very favorable to senior comprehensive exams when the arguments for them have been good and strongly negative otherwise. Petty and Cacioppo are able to show, in addition, that the different reactions of the high- and low-involvement students are due precisely to the fact that the former have thought more extensively about the arguments being made. One wishes one could be confident that the general public were as good at detecting weak arguments as were Petty and Cacioppo's ' "high-involvement" college students. But the reasons for doubt are great. First, the weak arguments used in Petty and Cacioppo's experiments were extremely weak, sometimes comically so. It took systematic effort to develop such weak but still coherent arguments, and political persuaders in real life cannot be expected to take similar pains. Bad as the arguments of many politicians may be, politicians (and their media consultants) try to be persuasive. In cases of real-life political controversy, citizens are likely to face two sets of opposing arguments that, when compared to those of a typical Petty and Cacioppo experiment, will all be ''strong." Second, most politics, at least in the contemporary United States, is notoriously low key and uninvolving. The stakes are theoretically high, but people find it hard to stay interested. (The evidence on this point was reviewed in Chapter 2.) In such "low-involvement" conditions, Petty and Cacioppo's work indicates that most people engage in "peripheral" message processing, that is, processing that ignores the intrinsic quality of arguments and uses superficial cues such as source credibility as the basis for accepting or rejecting messages. Third, the students in the Petty and Cacioppo experiments were judging issues that were rooted in their everyday experiences. (Other issues Petty and Cacioppo use are tuition increases and liberalization of dormitory visiting hours.) With respect to issues like these, virtually all students are fully capable, without any particular past attention to the issues, of responding in the manner of informed experts. This condition does not even remotely hold for most political issues, where the information and judgment necessary to reach reliable conclusions is beyond the direct experience of even the most attentive persons. Thus, the conditions that make possible Petty and Cacioppo's encouraging findings - weak arguments, and "receivers" who are both involved in and wellinformed about the issue at hand - are simply not present in typical situations of mass persuasion. On the contrary, real-world conditions, according to the work of Petty and Cacioppo and that of others, encourage reliance on peripheral cues, such as whether the person advocating a position is liberal or conservative, a union leader or a priest, or whatever (Belknap and Campbell, 1951-2; Campbell et al., 1960; Key, 1961; Mueller, 1973; Price, 1989; Gerber and Jackson, 1990; Pollock, Lisle, and Vittes, 1991; Page and Shapiro, in press). There is, then, solid empirical support for the assumption that citizens normally respond to new information on the basis of external cues concerning the implications of that information for their values and other predispositions, provided that, as Converse emphasizes, they are sufficiently attentive to politics to have learned the cues. Having stated a strong argument for why political awareness should be associated with resistance to persuasion, let me now state an equally strong caveat: The argument applies only to cases in which the contextual information necessary to evaluate an issue in light of one's predispositions is, for one reason or another, obscure. Thus, as we saw in Chapter 2, steadfast anticommunists were quite able to state opinions consistent with their predispositions when they were asked about ''stopping communism" in Central America. It was only when they were asked about "aid to the Contras," an obscure reference, that they had trouble. To take another example, one would expect strong age-related differences, independent of political awareness, in responses to a question about taxing social security benefits. The reason is that virtually everyone, even the least politically aware, would possess the contextual information necessary to answer this question in relation to their predispositions, in this case, nearness to retirement age. The extent to which contextual information is obscure may depend either on the nature of the issue - race, as Converse pointed out, is one area in which most people can understand what is at stake - or on the way a question is phrased, as in the example of aid to the Contras. Generally speaking, the more abstract the link between a predisposition and a related policy issue, the greater the amount or obscurity of knowledge necessary to perceive the linkage, or the more complicated the chain of reasoning involved, the more important political awareness is likely to be in regulating individual responses to political communications on that issue. Conversely, the more simple and direct the link between a predisposition and an issue, the less important awareness is likely to be in regulating responses to political communications on that issue. Although it is important to note that awareness can be expected to enhance resistance to persuasion only when the full significance of the issue or survey question is to some degree obscure, this qualification by no means robs the resistance axiom of its bite. Obscurity, in the sense I have indicated, is extremely common in politics. A3. ACCESSIBILITY AXIOM. The more recently a consideration has been called to mind or thought about, the less time it takes to retrieve that consideration or related considerations from memory and bring them to the top of the head for use. Conversely, the longer it has been since a consideration or related idea has been activated, the less likely it is to be accessible at the top of the head; in the limit, a long unused set of considerations may be completely inaccessible, which is to say, forgotten. This axiom appropriates for use in the model one of the best-established empirical regularities in cognitive psychology. General support for the basic idea is overwhelming and, as far as I can tell, undisputed. When an idea or concept has been recently used, seen, heard, or indirectly referenced, it is significantly more likely to be available for reuse than if it has not been recently activated (for reviews, see Higgins and King, 1981; Wyer and Srull, 1989). Note, however, an element of ambiguity in this axiom. Although specifying that use of one consideration can increase the accessibility of related considerations, it says nothing about what it means for different considerations to be re- lated. I am therefore implicitly relying on common understanding to determine when considerations are related to one another. A4. RESPONSE AXIOM. Individuals answer survey questions by averaging across the considerations that are immediately salient or accessible to them. This axiom, which completes the statement of my proposed model, implies that persons who have been asked a survey question do not normally canvass their minds for all considerations relevant to the given issue; rather, they answer the question on the basis of whatever considerations are accessible "at the top of the head." In some cases, only a single consideration may be readily accessible, in which case individuals answer on the basis of that consideration; in other cases, two or more considerations may come quickly to mind, in which case people answer by averaging across accessible considerations. An important feature of the Response Axiom is that it permits different people to respond to issue questions on the basis of different considerations - one, for example, emphasizing ideological concerns, another gut-level likes and dislikes, and yet another self-interest. This renders the model consistent with a growing literature indicating that such interpersonal heterogeneity is quite common (Graber, 1984; Rivers, 1988; Sniderman, Brody, and Tetlock, 1991; Hollis, 1991). Many readers will suspect that the top-of-the-head Response Axiom is too simple - as, indeed, it surely is. Psychologists working with data from laboratory studies and from experimentally controlled surveys have developed more complex and hence presumably more realistic models of how individuals process information and reach decisions. For example, Tourangeau and Rasinski (1988) have proposed a four-stage model in which individuals (1) interpret the question to determine what the issue before them really is, (2) canvass their minds for relevant thoughts, (3) integrate their thoughts into a coherent opinion, and (4) map that opinion onto the response options available in the question. Because features of the questionnaire can affect each of these steps, the questionnaire also affects what gets reported as public opinion. Although the Tourangeau and Rasinski model is still fairly simple, it may nonetheless be too complex for use in the context of mass opinion survey data. I say this because it is quite consistent with the evidence that Tourangeau and Rasinski cite that their four-stage process has only one important step: the retrieval from memory of a dominant consideration. So, for example, a conservative who happens to think about a government services question in terms of "welfare cheats" may already have done all he needs to do in the way of canvassing his mind for beliefs, integrating them into a coherent opinion, and mapping the opinion onto the given response options. Tourangeau and Rasinski are aware of their limited ability to distinguish empirically the steps in their model with survey data and do what they can to combat it. But my point remains that complex models may have only limited utility for general analyses of public opinion. Models that are still more complex, such as the forty-three-postulate information-processing model proposed by Wyer and Srull (1989), are even more dubious in the context of public opinion data. Analysts of mass opinion can profitably use such models for heuristic guidance in devising their models, but, in the end, it is necessary to make radical simplifications if the purpose is to engage in the rigorous analysis of typical public opinion data. If there is a threat to my simplified top-of-the-head Response Axiom, it comes from recent psychological studies of ''on-line" information processing. The argument here is that people do not form their attitude statements from ideas accessible at the moment of response but instead use a ' 'judgment operator" to continuously update their attitudes as they acquire new information; people are said to store these updated attitudes in memory and retrieve them as required by a given situation, including interview situations (Hastie and Park, 1986; Lodge, McGraw, and Stroh, 1989). Although a fair amount of evidence supports the on-line model, there are strong reasons for doubting that it holds generally within the domain of political attitudes. These reasons are best discussed after the evidence supporting my model has been presented. For the moment, however, I briefly note two of the most important. The first is that it is wildly unrealistic to expect citizens to use each piece of incoming information to update all of the ' 'attitudes" to which it might be relevant. Thus, for example, a news story about the suffering of homeless people would, in the idealized world of on-line processing, require updates of attitudes toward the welfare system, the value of big government, the efficiency of capitalism, the president's attempts to trim welfare spending, voluntary charity, the American way of life, among others - which is to say, many more subjects that a person could possibly rethink at the moment of encountering each new piece of political information. The second reason for doubting the applicability of the on-line model to political attitudes is that this model, with its notion that attitudes are simply "retrieved" from memory and reported to the inquiring interviewer, is quite obviously just a restatement of the conventional "true attitude" model, a model that, as I have been at pains to show, is simply not capable of accommodating the available evidence on the nature of mass political attitudes. The survey responses that people make within the proposed model may reasonably be described as attitudes or opinions, in that they represent people's true feelings at the moment of answering a given survey question; they could not, however, be described as "true attitudes," in the technical sense of the term, because survey responses are not assumed to represent anything more than a single aspect of people's feelings toward a given attitude object. Perhaps the most apt description of a survey response within the proposed model is "opinion statement." This term implies that the expression of opinion is genuine without also implying that it either represents prior reflection or is destined for a long half-life. The phrase "attitude report" has similar virtues. Opinion statements, as conceived in my four-axiom model, are the outcome of a process in which people receive new information, decide whether to accept it, and then sample at the moment of answering questions. For convenience, therefore, I will refer to this process as the Receive-Accept-Sample, or RAS, Model. 

## HOW THE MODEL IS USED IN THIS BOOK

The model I have outlined consists of four very general claims about how people acquire information from the political environment (in the form of persuasive arguments and cues) and transform that information into survey responses. In the remainder of the book, I use these axioms to explore and explain numerous aspects of mass opinion. In particular, I will use the axioms to explain the distributions of mass opinion that may be expected to occur in various kinds of political environments - for example, a political environment in which people are exposed to two equally intense streams of competing liberal and conservative messages on a given issue; a political environment in which most of the messages one-sidedly favor a given issue; and an environment in which the proportions of liberal and conservative messages are changing, thereby producing attitude change in the mass public. The four axioms, standing by themselves, have limited analytical utility; but they come to life under these various configurations of the flow of political information. The method of the book, then, is to develop the deductive implications of the four basic axioms for a given, highly specific set of conditions; review evidence indicating whether or not these implications are empirically correct; and present new evidence as necessary and possible to resolve outstanding empirical questions. At a few points in the analysis, it will be necessary to supplement the four axioms in nonfundamental ways. For example, I will need in Chapter 7 to stipulate a functional form for the relationship between political awareness and reception of political messages. More and less complicated operational models will also be built from the axioms at various points in the book, depending on the strength of the data available to test the models. But no significant new substantive claims about public opinion will be introduced. The burden of the book will be to show how various aspects of public opinion, some well-established and some novel, can be deduced from the four axioms, given particular information flows - that is, particular streams of liberal and conservative communications - in the political environment. The argument to be made from the RAS model may be previewed as follows. It follows from the Response Axiom that the probability that a person will support or oppose a given policy depends on the mix of positive and negative considerations available in the person's mind at the moment of answering a question about it. If, for the moment, we overlook the probability of nonresponse (which occurs when no considerations are immediately salient in memory), and assume also that every consideration a person has internalized is as likely to be sampled as any other, then the probability of a liberal response by a given person is L Prob(Liberal response) =  L/(L+C) where L and C refer to the number of liberal and conservative considerations available in the person's mind. (I reiterate that here, as elsewhere in this book, liberal and conservative are simply labels for the directional thrust of ideas; a person may use a liberal consideration as the basis for a liberal response even though she is not, in any deeper sense, "a liberal.") The balance of liberal and conservative considerations in people's minds depends on both society-level and individual-level variables. The key societal variables are the intensities of liberal and conservative information flows in the political environment with respect to a given issue. The key individual variables are political awareness and political predispositions. More aware persons will be exposed to more political communications (via the Reception Axiom) but will be more selective in deciding which communications to internalize as considerations (via the Resistance Axiom). Thus, politically aware citizens will tend to fill their minds with large numbers of considerations, and these considerations will tend to be relatively consistent with one another and with the citizens' predispositions. Less aware persons will internalize fewer considerations and will be less consistent in doing so. As a result, more aware people will be more likely to be able to state opinions, and more likely to state opinions that are ideologically consistent with their predispositions. Changes in the relative intensity of liberal and conservative communications on an issue will produce changes in the kinds of considerations people form, which will in turn produce changes in the opinion statements they make. One of the things that gives the RAS model its strength is its ability to forecast that different segments of the public will change their attitudes in different amounts and even different directions, depending on their political awareness, their political values, and the particular changes in information flow that have occurred. Thus, the four basic postulates of the sampling model, unprepossessing as they are, entail quite definite claims about how public opinion forms and changes, as we will now begin to see. 

# Chapter 4: Coming to terms with response instability

Respondents to the 1987 NES pilot study were asked to answer what academic analysts of public opinion will recognize as an entirely standard question: Some people think the government in Washington should cut government services, even in areas such as education and health care, in order to reduce the deficit. Others think government services should be increased. In an unusual twist, however, respondents to this survey were not permitted to give an immediate answer to the question. Instead, the interviewer continued: Before telling me how you feel about this, could you tell me what kinds of things come to mind when you think about cutting government services? (Any others?) The interviewer wrote down respondents' remarks verbatim, and then asked: Now, what comes to mind when you think about increases in government services? (Any others?) At this point, the original question was repeated and the respondents were, at last, permitted to render a simple dichotomous judgment on the matter of government services. But in the meantime, each individual had revealed what the issue of government services meant to him or her at the moment of answering a standard closed-ended question about it. Because every respondent was asked the same questions again four weeks later, these probes make it possible to see how their thinking on the issue might have changed over time. The openended comments elicited by these probes constitute some of the best evidence currently available on what citizens' survey responses mean and why they are so beset by vagaries. As it happened, I was at the University of Michigan's Survey Research Center when completed interviews from this study began to arrive from the field office.l The first pair of these interviews involved a person who described himself - or herself, I have no way of knowing - as a teacher, and who spoke quite emphatically in favor of higher levels of services and spending. The country was facing an educational crisis, the respondent said, and, as a teacher, he or she knew that more education expenditures were drastically needed. Any cuts in federal services or spending would inevitably reduce the already inadequate amounts of money available for education, and that would be a disaster. What was striking about this interview was that it seemed to exemplify the kind of highly crystallized "true attitude" that many opinion researchers implicitly take to be the norm. Yet, in responding to the same questions several weeks later in the second wave of the survey, the teacher favored reductions in government services. And in open-ended remarks, the same respondent now spoke just as emphatically as in the earlier interview, except taking the opposite line. Government was too big, he or she asserted, and something had to be done to prune it back or it would take over everything. There was no reference to the educational crisis that had preoccupied the respondent a few weeks earlier.2 I read over these remarks with a member of the NES staff, who immediately concluded that a mistake had been made. 'Those turkeys downstairs got the case ID's on the interviews scrambled," the person declared. "These are different respondents." It turned out, however, that the case ID's were correct. Although perfectly stable in remarks about two other questions, even using sometimes identical language to discuss them, the teacher-respondent had changed his or her response on the services item, though without indication of having done so knowingly. The respondent appeared simply to think about the issue differently in the second interview, and so to reach a different conclusion about it. This respondent turned out to be representative of many others. Like that first respondent, most citizens appeared not to have "just one attitude" toward political issues, and like him or her, they appeared to base their survey responses on whichever of their multiple and sometimes conflicting attitudes was most immediately salient to them. The model I have proposed is an attempt to be faithful to this and similar evidence. It abandons the notion that individuals typically possess preformed attitudes that they simply reveal when asked by a pollster to do so. It instead adopts the view that people possess numerous, frequently inconsistent "considerations" relating to each issue, and that they base their survey responses on whichever of them are at the top of the head at the moment of response. I should add that nothing in the model I have proposed prevents individuals who pay great attention to an issue from developing a perfectly homogeneous set of considerations with respect to every aspect of that issue, so that every consideration that comes to mind impels them toward the same opinion statement. In fact, in the limiting case of very great attention to an issue, this is exactly what, according to the RAS model, should happen. Persons who are highly engaged with an issue may thus develop the crystallized attitudes that most opinion researchers take to be the norm. But for the majority of persons on the majority of issues, inconsistencies in their considerations concerning different aspects of a given issue remain unresolved and probably unrecognized. Their responses to typical survey questions then depend on which aspect of the issue is most salient to them, where saliency depends partly on purely chance factors, such as what appeared on television the night before or what happened to them that morning at the office, and partly on systematic factors, such as how the question has been framed or what related questions have been asked in immediate proximity to it. This model, as I show in this and the next chapter, can account for a wide range of evidence concerning the nature of political attitudes. Much of the evidence presented in this chapter will be familiar to professional students of public opinion, but some of the most important of it - that involving attempts to make direct measurements of the considerations that people bring to bear in answering survey questions - comes from the 1987 NES pilot study, which is not widely familiar. It is therefore necessary to pause to describe that study.

## THE 1987 PILOT STUDY

In recent years, the National Election Studies at the University of Michigan has regularly conducted small surveys in nonelection years for the purpose of testing new survey questions and ideas. Space on the survey is allocated by the NES Board of Overseers, which solicits proposals from the community of public opinion specialists and allocates survey time to the proposals it judges most promising. The data described below were collected on the 1987 pilot study of the NES under a proposal submitted by Stanley Feldman of the State University of New York (SUNY) Stony Brook and me, and are, of course, publicly available through the Inter-university Consortium for Political and Social Research at the University of Michigan. The 1987 pilot study was a two-wave telephone survey of respondents who had earlier participated in the 1986 National Election Study. The first wave interviewed 450 persons in early summer, the second wave reinterviewed 357 of these people a month later. In this survey, respondents were asked a series of standard issue questions on federal job guarantees, the proper level of government services, and aid to blacks. Immediately afterward, a random half of respondents were asked: Still thinking about the question you just answered, I'd like you to tell me what ideas came to mind as you were answering that question. Exactly what things went through your mind? This probe was designed to reveal the considerations that were most important in determining respondents' answers. In the other half of the survey, interviewers read the items in the usual way, but, without waiting for the respondent to answer, they asked the respondent to discuss particular phrases and ideas in the question, as indicated in the opening paragraph of this chapter. After administration of the "stop-and-think" probes, as they have been labeled,3 the interviewer reread the entire question and recorded the person's reply to it. Feldman and I designed the two types of open-ended questions for different purposes. The "retrospective" probes, which were posed after people had already answered the question in the normal way, were designed to elicit a sort of "memory dump" of what was on people's mind at the moment of response. The stop-and-think, prospective probes were asked before respondents could answer the question and were designed to induce people to think more carefully about their opinions than they ordinarily would; the expectation was that the extra thought might make people's responses more reliable. The stop-and-think probes were also intended to elicit, as nondirectively as possible, the range of considerations that a person considered relevant to the issue at hand. Interviewers wrote down as faithfully as possible all responses to the openended probes.4 The transcribed comments were subjected to an elaborate classification scheme, with as many as four comments coded in connection with each probe. Respondents averaged about four codable comments per policy item, with almost all respondents offering at least one codable comment.5 Each comment or remark was rated on several variables by staff coders at the Institute for Social Research (ISR) at the University of Michigan. Because the coding project was considered a difficult one, only experienced coders were used. The most important and simplest variable was "directional thrust of comment," which indicated which side of the issue, if any, the remark tended to support. Although coders were instructed to note ambivalence, confusion, and nonsubstantive concerns, three-quarters of all comments were assigned a clear directional thrust. About 8 percent of remarks were uncodable because, although a directional thrust may have been intended by respondents, coders could not discern what it was. The other key coding classification was the "frame of reference" code, a variable that included more than 140 categories and tried to capture the substantive content of each remark.6 About one-tenth of all interviews were double-coded. Although exact reliability data are not available, the coding supervisor reported a "difference" between coders on 10 to 15 percent of all cases. This difference rate was regarded as reasonable for difficult open-ended material.7
These data, although collected for the specific purposes to which they are put below, are not without limitations. The most obvious is the difference rate between coders. Although within the normal range, it is high enough to seriously undermine the ability to make precise tests of certain hypotheses, as will become apparent. Less obvious but probably more important is the difficulty in sharply distinguishing one "consideration" from another. When two remarks have opposing thrusts - one favoring a policy and the other opposing it - this is no problem. But in some cases, people made several consecutive remarks on the same side of the question. Do these remarks represent separate considerations, or simply elaborations on a single consideration? Even a person listening to the interviews as they were taking place, as I did, would sometimes have difficulty being certain; for coders working from an imperfect transcript, the problem is more serious. Hence, although the following analysis sometimes attempts to count the number of pro- and con- considerations that individuals raise, the reader should bear in mind that the data on which these counts depend are, at best, approximate. Three other, more common data problems also merit notice. One is small sample size. After normal rates of attrition across waves and "no opinion" responses, there were just over a hundred complete cases on the retrospective side. This led to a second difficulty. Less politically aware respondents drop out of surveys at disproportionately high rates; anticipating this problem, the pilot study oversampled less aware respondents (by using their scores on an information test in the regular 1986 study). But even so, the low-information respondents who survived three interviews and who answered the target items on both waves of the pilot are a highly selected and hence unrepresentative group of politically unaware persons. In particular, they are likely to be more interested in the issue, all else equal, than persons who had equal scores on the awareness scale but either dropped out of the study or failed to answer the question both times. Finally, the unusually short time between interviews, one month, resulted in less than the usual amount of response instability. All three of these problems reduce statistical power to observe and understand over time response instability, the key dependent variable in this analysis. Notwithstanding these limitations, the first two of which are inherent in any attempt to gather data on considerations from a nationally representative sample, the measures of considerations available in this study constitute the best data of which I am aware - in fact, the only available data - for testing certain of the expectations derived from the RAS model. Despite their limits, they provide some revealing glimpses of the microfoundations of political attitudes.

## FIRST DEDUCTIONS FROM THE MODEL 

In the remainder of this chapter, I use the axioms of the Receive-Accept-Sample (RAS) model, as outlined in the previous chapter, to make testable deductions concerning the nature of citizens' responses to survey questions. I then proceed to test empirically these deductions. (For easy reference, the axioms of the RAS model are restated here as Table 4.1.) The Receive-Accept-Sample Model is, as explained, a set of claims about how citizens acquire "information" and convert it into attitude statements, which is to say, it is a type of information-processing model. Attitude statements on particular issues therefore depend fundamentally on the amount and direction of information available to the public on each issue. Given this, one cannot test the model without making definite assumptions about the information environment that sustains citizens' attitudes on a given issue. For purposes of this chapter, I make the following simple assumption about this environment: that it consists of moderately intense, temporally stable information flows favoring both the liberal and the conservative side of each issue. By moderately intense, I refer to information flows that involve neither dominating headline stories (for example, the Iran-Contra scandal of 1987 or the Persian Gulf War) nor obscure and esoteric stories (such as congressional debates over the organizational structure of the Commerce Department). Thus, in the case of a survey item about the proper level of government services, my assumption will be that there is a steady but not overwhelming stream of messages that give individuals reasons both to favor increased government services (news stories about children living in poverty, for instance) and to favor decreased government services (news stories about the federal budget deficit). By temporally stable information flows, I mean that the intensities of the opposing messages are stable over the period prior to the survey. (When information flows change over time, they produce attitude change, which is the topic of investigation in later chapters.) Under the assumption, then, of stable, moderately intense information flows on both sides of a given issue, what follows from the RAS model about the nature of citizens' attitude reports on this issue? My first deduction concerns what I see as a fundamental claim concerning most people's attitudes on most issues, namely a tendency toward some degree of ambivalence. From A2, the Resistance Axiom, we know that individuals can reliably resist the arguments to which they are exposed only to the extent that they possess "information" about the implications of those arguments for their predispositions. We also know from Chapter 2 that, as a matter of fact, most Americans do not rate very highly on political awareness. From these two points it follows that citizens will be unlikely to exhibit high levels of resistance to arguments that are inconsistent with their values, interests, or other predispositions. This implies that, in an environment that carries roughly evenly balanced communications on both sides of issues, people are likely to internalize many contradictory arguments, which is to say, they are likely to form considerations that induce them both to favor and to oppose the same issues. This deduction from the model, Dl, will be referred to as the Ambivalence Deduction. (Subsequent deductions from the model are labeled by means of the deduction number in parentheses immediately following the inference.) The anecdote of the teacher-respondent who, at different times, both favored and opposed increases in government services has already given us a hint that the ambivalence deduction is correct. The question we must now ask is: How common is the internally conflicted attitude pattern exhibited by the vacillating teacher? Hochschild's (1981) study of citizens' attitudes toward equality, which was based on lengthy open-ended interviews with twenty-eight persons, strongly suggests that it is quite common. Consider her account of the attitudes of one of her subjects toward government income guarantees: Vincent Sartori cannot decide whether or not the government should guarantee incomes, because he cannot decide how much weight to give to the value of productivity. He believes that the rich are mostly undeserving and ... yet he is angry at "welfare cheats" who refuse to work. . . . Caught between his desire for equality and his knowledge of existing injustice, on the one hand, and his fear that a guaranteed income will benefit even shirkers, on the other, he remains ambivalent about policies toward the poor, (p. 252) One of Hochschild's principal conclusions in her study was that most individuals' political beliefs are characterized by similarly high levels of "ambivalence." People would, Hochschild found, readily provide answers to fixedchoice questions, but given the opportunity to talk, people do not make simple statements; they shade, modulate, deny, retract, or just grind to a halt in frustration. These manifestations of uncertainty are just as meaningful and interesting as the definitive statements of a belief system, (p. 238) Depth interviews such as Hochschild's are, of course, susceptible to many criticisms, including the possibility that aggressive probing might have induced some people to say things they didn't actually feel very strongly. It would be useful, therefore, to corroborate Hochschild's conclusions from survey data. Open-ended interview data from the 1987 NES pilot study, in which people describe their thoughts as they answer survey questions, afford several ways of doing so. Although these data do not, in their aggregate form, have the richness and human feel of Hochschild's depth-interview data, they have the advantage of having been derived from a nationally representative sample by means of standardized, nonreactive, and relatively nonintrusive probe techniques. Perhaps the most straightforward test for the existence of ambivalence is simply to make a count of the number of opposing remarks by a person that can be paired against each other. If, for example, a respondent makes two open-ended comments favoring higher levels of government services and two that indicate a desire to cut government services, his score on the conflict measure would be 2. If he makes three (or more) on one side of the issue and only two on the other, the conflict score is still 2 because the number of opposing comments that can be paired remains two. Any conflict score above zero indicates that the person experiences some degree of internal conflict on the given issue. It is also possible to make a count of the number of times people spontaneously express ambivalence or difficulty in making up their minds. Such remarks indicate that the person is caught between opposing ideas. Coders were instructed to be alert for such conflict, and were given a special code for use in capturing it, as follows: Mention indicates ambivalence, conflict (e.g., "I see merit in both sides"; "that's a tough question"; "depends"; "both are valid points"). Finally, the frame of reference codes included special codes, designated "star codes," that indicate a directional thrust to the comment, but also some ambivalence with respect to that direction. Star codes were intended to cover cases in which respondents had a preference but were clearly paying some attention to the other side of the issue. Instructions to coders for use of star codes are as follows: A STAR CODE is used only for cases in which there is a single thought or comment that encompasses two opposing elements, e.g., "Although I think X, I nevertheless favor Y." Star codes are used for comments in which Respondent] sees two sides to an issue.8 Examples of star codes are "People should try to get ahead on their own, but government should help when necessary" and respondent "admits problem(s) with any program or type of program, but insists it is worthwhile anyway."9 A count of the star-coded remarks may thus be considered an indicator of degree of a person's internal conflict on an issue. From these three measures one can create a fourth: a count of the ambivalence indices on which a person scored + 1 or higher. Because internal conflict and ambivalence are equally consequential whether they occur within the course of one interview or across separate interviews, and because we wish to capture as many as possible of the conflicting considerations that are in people's minds, all four of these count indices have been calculated across responses from both waves of the survey. Distributions of respondents' scores on these four measures of ambivalence are shown in Table 4.2. As can be seen, respondents exhibited substantial amounts of internal conflict on all measures, a result that corroborates Hochschild's contention and thereby offers additional, clear support for the Ambivalence Deduction, Dl. Even on the more conservative evidence of the retrospective probes, which involve only one query in each wave,10 the summary measure indicates that 36 to 49 percent of respondents are to some degree ambivalent on these three issues. And this is surely an understatement. What the retrospective probes capture, as indicated, is the reason the person has answered the item as he just has; they cannot capture anything like the full range of ideas in a person's head. However, the stop-and-think probes were designed to tap a wider range of the ideas in people's minds; on evidence from them, roughly 75 percent of respondents are at least somewhat conflicted on the three issues. And this is still probably an understatement, since further probes and more reliable coding of open-ended remarks would almost certainly disclose further indications of conflict. Granted, then, most people are to some degree ambivalent about the political issues they confront. What else follows from the model? Let us consider next the relationship between the responses people make to closed-ended policy questions and the ideas that are at the top of their heads as they do so. The model leads us to expect a strong relationship between these two attitude measures because A4, the Response Axiom, claims that people answer survey questions on the basis of the ideas that are most salient to them at the moment of response. Thus if, for example, a person makes two openended remarks favoring the liberal side of the issue and one favoring the conservative side, we would expect, on average, that the person will take the liberal side of the issue on the closed-ended item. Similarly, a person who raises mostly conservative considerations would be expected to choose the conservative option on the closed-ended item. This is D2, the second deduction from the model. This deduction is important because, if it turned out that there was no relationship between people's open-ended remarks and their choices on closed-ended items, the ambivalence embodied in the open-ended remarks would be inconsequential. Although D2 is so straightforward that it may seem hardly worth testing, it is not obvious that it can be confirmed. Social psychologists, working in the domain of personality evaluation, have turned up many cases in which people's open-ended thoughts are completely uncorrelated, or occasionally even negatively correlated, with their responses to closed-ended questions about the same subject (Hastie and Park, 1986).n The explanation given is as follows: People form personality evaluations "on-line" as they encounter each new bit of relevant information. These evaluations are then stored as long-term attitudes and used as the basis of attitude reports, when such attitude reports are subsequently requested. There is, therefore, no necessary relationship between the information that is immediately accessible in memory and the attitude reports that people make (see also Lodge, McGraw, and Stroh, 1989). All of this is, of course, contrary to the RAS model. For reasons outlined in Chapter 2, the RAS model assumes that, at least in the domain of political issues, people do not possess preformed, long-term attitudes on most of the issues on which pollsters query them, and so base their attitude reports on the considerations that are immediately salient to them. Thus, in the RAS model, there should be a close relationship between considerations and opinion. Data from the 1987 pilot study, in which people described their thoughts as they answered survey questions, have been used to test these competing expectations. An additive index was created to summarize the directional thrust of each person's open-ended remarks on each issue. This index was then correlated with responses to the closed-ended policy questions, with results that are shown in Table 4.3. In the stop-and-think condition, in which people talked about the meaning of the question before answering it, Pearson correlations between the index and its associated item in each wave of the survey average .42 over the three items. When an index of all remarks over both waves of the survey is correlated with an index consisting of the sum of the two closed-ended policy items, the correlations average about .51.12 Given that the closed-ended items in these tests are essentially dichotomies - a few people volunteered responses of "both" and "in between" - these are sizable correlations. When, in the retrospective condition, respondents were asked, just after answering the question, to say what they were thinking about as they answered it, the correlations between their remarks and their closed-ended responses averaged .75. When remarks and items were summed and correlated across both waves of the survey, the correlations averaged .80. Although correlations from the retrospective data are higher, those from the stop-and-think data are the stronger evidence for D2. For in this case individuals cannot be covertly justifying a response just given; they are simply explaining in their own words "what comes to mind" when they think about the issue. Yet despite this, and contrary to the evidence from the domain of personality evaluation (Hastie and Park, 1986), people's political attitude statements are significantly correlated with "top-of-the-head" ideas. Thus, although I do not claim that the confirmation of D2 is either deeply surprising or definitive evidence for the RAS model, it is a confirmation that could not have been taken for granted and is therefore useful evidence on behalf of the model.

### Table 4.1. Axioms of Receive-Accept-Sample (RAS) model 
  - Al. Reception Axiom. The greater a person's level of cognitive engagement with an issue, the more likely he or she is to be exposed to and comprehend - in a word, to receive - political messages concerning that issue.
  - A2. Resistance Axiom . People tend to resist arguments that are inconsistent with their political predispositions, but they do so only to the extent that they possess the contextual information necessary to perceive a relationship between the message and their predispositions.
  - A3. Accessibility Axiom. The more recently a consideration has been called to mind or thought about, the less time it takes to retrieve that consideration or related considerations from memory and bring them to the top of the headfor use.
  - A4. Response Axiom. Individuals answer survey questions by averaging across the considerations that are immediately salient or accessible to them.

## RESPONSE INSTABILITY

As I have indicated, instability in people's attitude reports over time is one of the most deeply worrisome, if not routinely emphasized, empirical findings of modern survey research. The existence of widespread ambivalence, in conjunction with the Response Axiom, provides a ready explanation for it. If people form conflicting considerations on most issues, and if they base their survey responses on whichever of these considerations happen to be at the top of the head at the moment of response, one should expect a fair amount of variability in people's responses to survey questions (D3). This deduction has been strongly confirmed on numerous occasions, as illustrated in Table 2.1 and in various publications (Converse, 1964; Achen, 1975; Dean and Moran, 1977; Erikson, 1979; Judd and Milburn, 1980; Judd, Milburn, and Krosnick, 1981; Feldman, 1989; Zaller, 1990). The model also has strong implications for the structure of this response instability so long as the flow of information in the political environment remains steady. The qualifying phrase is extremely important. If people are exposed to a shifting balance of liberal and conservative communications, the balance of considerations in their minds will shift in the direction of the more recent communications, and this will bring about systematic attitude change. But if the flow of communications remains steady, the balance of positive and negative considerations in each person's mind should be, on average for each given issue, roughly the same at one point in time as at another. What will then vary, according to the model, is the particular consideration that happens to be at the top of the head at a given interview. If this is true, we should expect to find a fair amount of purely chance variation around a stable central tendency (D4). There is wide agreement among researchers who have investigated this matter that deduction D4 is correct. In applications of models designed to separate chance variability in attitude statements from long-term change, it has repeatedly been found that response instability consists almost exclusively of chance variation around a largely stable central tendency (Converse, 1964; Achen, 1975; Dean and Moran, 1977; Erikson, 1979; Judd and Milburn, 1980; Judd, Milburn, and Krosnick, 1981; Feldman, 1989; Zaller, 1990; see, however, Krosnick, 1988). Thus a person's long-term average score on a seven-point scale may be 5, but the score may fluctuate considerably around that long-term average - say, between 3 and 7 - over repeated interviews. An additional deduction from the RAS model is that more politically aware persons will exhibit less chance variability in their survey responses. This deduction may be reasoned as follows: More aware persons are more likely (from axiom Al) to possess the cueing messages necessary to respond to incoming information in a critical manner. As a result, they are more likely than less informed persons to reject information that conflicts with their values and to accept only information that is consistent. This will tend to increase the homogeneity of the considerations from which politically aware persons sample, which will tend to increase response stability. We have, then, three deductions: Better informed persons are more likely to possess the cueing information necessary to reject communications inconsistent with their values (D5); this will make it more likely that they will form considerations that are homogeneously consistent with their values (D6), and this homogeneity will lead, inter alia, to greater response stability over time (D7). Deduction D5 is easy to test, as shown in Table 4.4. The data in the top panel of this table were generated from a series of questions in the 1988 National Election Study, the first of which asserted: Some people feel the government in Washington should see to it that everyone has a job and a good standard of living. Others think the government should let each person get ahead on his own. Respondents were next asked to state their position on a seven-point scale anchored by the two polar positions, and then, in a final stage, they were asked to indicate the position of several prominent political figures or groups on this scale, including Ronald Reagan, George Bush, Michael Dukakis, Jesse Jackson, and each of the political parties. As can be seen, highly aware persons were, as expected, much more likely than unaware ones to know that support for job guarantees is the position of the Democratic Party and its leading figures, and to know also that Republicans do not normally endorse this idea. For many Democrats and Republicans, this is knowledge that may affect their response to communications touching on the general issue of job guarantees. As Table 4.4 also shows, a similar pattern held for the issue of defense spending. To test D6,1 created a measure of ideological consistency at the level of considerations. I began by classifying each person's considerations as ''consistent" with their underlying ideology or ''inconsistent." For example, if a person who scored liberal on a social egalitarianism scale (described in Measures Appendix) said that "blacks need special aid to make up for the effects of past discrimination," it would be counted as a consistent consideration; but if a conservative made the same remark, it would be an inconsistent consideration, since it runs against the grain of conservative ideology. A measure of consistency was then constructed as follows: (Consistent remarks) (Consistent remarks) + ^ (Inconsistent remarks) This consistency measure, which runs from 0 to 1, gives the proportion of a person's remarks that are consistent with his underlying ideology. Figure 4.1 shows the relationship of these consistency scores to political awareness. As expected, respondents who are low on political awareness exhibit little ideological consistency in their underlying considerations; in fact, they are about as likely to mention ideologically inconsistent considerations as consistent ones. Highly aware respondents, by contrast, exhibit a fair degree of consistency, though not so much as to violate the ambivalence deduction.14 Lusk and Judd (1988) have reported other confirming evidence for D6. Existing literature also provides clear support for D7. Although some research failed to find any relationships between political awareness and response stability (Achen, 1975; Erikson, 1979), three studies, each using a different dataset, have now found statistically reliable evidence that more politically aware persons exhibit less random instability in their closed-ended attitude reports, thus supporting D7 (Dean and Moran, 1977; Feldman, 1989; Zaller, 1991). The chain of reasoning that led to D7 has some additional testable implications. If, as was argued, more aware persons are more stable in part because they are more likely to possess the cueing messages necessary to develop homogeneous pools of considerations, then the population as a whole should be able to develop more stable attitudes for issues on which partisan elites divide sharply and clearly, thereby providing clearer message cues for everyone. Conversely, attitude stability should be weaker for issues on which partisan divisions are hazy or nonexistent, because in such cases the public gets few message cues (D8). Using two-wave panel data from the United States and Sweden, Niemi and Westholm (1984) confirm that response instability is greater for issues on which partisan cues are weaker.15 Thus, the extent to which ordinary citizens  develop stable attitude reports does, as inferred from the model, partly depend on the cues conveyed to the public by elite discourse. In the argument for D7, political awareness is simply a proxy for attention to an issue. Thus, any factor that is also associated with greater attention to an issue should produce the same effects as greater political awareness. One such factor is the extent to which an issue is relatively "close-to-home," in the sense that almost everyone in the public follows it and thinks about it a fair amount. When the degree of public attentiveness to an issue is generally high, it follows that attitude statements on this issue will, in the public as a whole, exhibit less variability, all else equal, than will attitude statements on a more remote or abstract issue (D9). The tendency of attitude statements on race, abortion, and drugs to be more reliable than other types of attitude statements may be taken as supporting evidence for this deduction (Converse, 1964; Converse and Markus, 1979; Feldman, 1989). By parallel logic, the model also implies that individuals who care more strongly about issues, or who are members of what Converse has called "issue publics," will pay more attention to issues and hence exhibit less chance variability in their attitude statements about these issues (D10). Initial evidence from Converse (1964) and Schuman and Presser (1981) seemed to support this expectation. However, Krosnick's (1988) more sophisticated probing of the question, which distinguishes random response variation from actual attitude change, produced disconfirming evidence. His analysis of data from the three-wave 1980 NES panel study, as well as other data, concluded that people who care more about an issue exhibit more rather than, as the RAS model anticipates, less random variability in their attitude reports. To find the reason for Krosnick's unexpected findings, I examined the 1980 panel data. What I discovered was that people who rated issues as extremely important were hardly more knowledgeable about them than people who said they were unimportant. For example, someone who rated toughness with Russia at 100 (the top rating) on the importance scale was only about 13 percentage points more likely to know that Ronald Reagan was to the right of Jimmy Carter on this issue than was a person who rated it at 25 on the importance scale (25 was the lowest importance rating given by any significant number of respondents). On one item, government services, there was no relationship at all between importance and knowledge of where Carter and Reagan stood on the issue.16 The reason for Krosnick's unexpected finding on response stability now seems clear: In arguing that people who regard an issue as important should be more stable in their response to it, I was assuming that they would also be more cognitively engaged with that issue. If this intervening condition is not met, the RAS model provides no expectation that these people will be more stable in their attitude reports.I7 These findings on the noneffects of issue importance on response stability underscore an important point about the RAS model: It is cognitive engagement with an issue, rather than concern or feeling about it, that drives the processes captured by the model. To this point, my analysis of response instability has focused on the effect of awareness and issue concern on random response fluctuation. But if less aware persons exhibit greater chance fluctuation, shouldn't they also exhibit greater susceptibility to enduring or systematic attitude change?18 Perhaps surprisingly, the answer to this question is no, or more precisely: No, not over the long run in a stable informational environment. For if, as the analysis of this chapter has explicitly assumed, information flows are stable over time, then all individuals, who are idealized in the model simply as "information processors," must remain near their equilibrium points. People's responses to particular questions may, for the reasons just given, vary stochastically around their equilibrium points, but the equilibrium points themselves should remain constant as long as the environment remains stable (Dll). The qualifying phrase "over the long run" is important here. In practice, the flow of communications will always have some short-term lumpiness and minor unevenness. (If the unevenness is great, it produces aggregate changes in mass attitudes, a topic analyzed in later chapters of this book.) Thus, if a person becomes unemployed, or sees a compelling news program, it may raise the salience of a particular consideration for a few days or perhaps a few months. But in the long run, the person should encounter countervailing communications that raise other considerations and restore opinion to its long-term mean. As a result of this lumpiness in the flow of communications, the average of salient considerations in people's minds will normally be near but not quite at its theoretically expected equilibrium. The regression of this average to its equilibrium point, which would take some time to occur, could give a misleading impression of gradual true attitude change, if attitude measurements were spaced closely enough to capture it. Thus, the expectation that susceptibility to real attitude change not vary by level of awareness or issue involvement would hold only for measurements that were fairly widely spaced. My investigation of attitude stability in the 1972-74-76 NES panel, in which attitude measurements were spaced at two-year intervals, supports this argument: Awareness had no effect on susceptibility to systematic attitude change which is to say, the stability coefficients in Wiley-Wiley estimates were near 1.0 and did not vary by respondents' level of political awareness (Zaller, 1986). There is, then, a fair amount of evidence that is consistent with the notion that response instability over time arises from a tendency of people to base attitude reports on a quick and incomplete sampling from a pool of internally conflicted considerations. So far, however, we have seen no direct evidence that people's attitudes are unstable for this reason - no evidence, that is, showing that instability occurs because people call to mind different considerations when thinking about a given issue at different times. One way to check this claim is to see whether changes in the directional thrust of people's open-ended remarks are associated with changes in the direction of their closed-ended remarks (D12). Thus, a person who makes mostly liberal comments when discussing a policy issue at the first interview and mostly conservative remarks at the second interview would be expected to change her closed-ended response from liberal to conservative as well. To test this expectation, I use the following model: Attitude2 = b0 + b1 Attitudei + b2 Considerations! + b3 Considerations2, where considerations are measured at time 1 and time 2. A large coefficient on b3, in conjunction with a moderate estimate for b2, would indicate an important role for immediately salient considerations in explaining departures from the closed-ended survey responses made in the initial interview. As can be seen in Table 4.5, the data tend to fit this pattern.19 Another test of the mechanism that, as I claim, is responsible for response instability is to check whether people who exhibit higher levels of internal conflict in their open-ended remarks are more likely to be unstable in their closedended survey responses. To create a measure of consistency of open-ended remarks, the following calculation was made for each respondent who answered the open-ended questions on both waves of the survey. abs(sum(Liberal remarks) —sum(Conservative remarks)) / sum(Liberal) + sum(Conservative) + sum(Ambivalent) A score of 1.0 on this measure would indicate that the person's remarks were either all liberal in their thrust or all conservative, while a score of 0 would indicate that the person had made an equal number of liberal and conservative remarks. Persons achieving the score of 1.0 should be perfectly stable in their responses to the closed-ended items. People who mention an equal number of opposing considerations should be stable only as often as could be expected by chance alone, which is 50 percent of the time (D13). The data for this test are shown in Table 4.6. In five of six tests, the measure of internal consistency is associated with a statistically significant increase in response stability; in the sixth case, the relationship achieves marginal statistical significance (p = .07). These results, however, fall short of expectations. Particularly on the stop-and-think side, response stability does not vary, as expected, between a floor of 0.50 and a ceiling of 1.0. Why do we observe a shortfall from expectations, and why is it greater when questions are asked in the stop-and-think format? The most likely explanation is a mundane type of measurement error. As earlier reported, coders disagreed on the coding of 10 to 15 percent of all openended remarks. Such error obviously impairs our ability to determine which respondents should be perfectly stable and which not. It would, therefore, strengthen our confidence in D13 if it could be shown that the items having the highest level of coding error also produced the largest shortfall from theoretical expectations in Table 4.6. Although direct data on coding errors are not available at the level of individual items, there is a way of estimating item-level error rates indirectly. In cases in which coders were unable to assign a directional thrust to remarks even though one was presumably intended, they declared the remark directionally uncodable. The rate of such uncodable remarks varied from a low of 2 percent for one item to a high of 16 percent for another. These item-level rates of uncodable responses may be taken as a general indicator of the difficulty of assigning accurate codes to other remarks associated with each given item. We should expect, then, that the shortfall from theoretical expectations in Table 4.6 is greatest for those items with the highest levels of directionally uncodable remarks. Figure 4.2 confirms that this is the case. The independent variable in that figure consists of the item-level rates of uncodable remarks. The dependent variable consists of the slopes (one for each item) obtained from regressing item stability on the consistency of the person's considerations; thus, regression coefficients have been used to summarize the relationships between stability and consistency in Table 4.6. As can be seen, these consistency-stability relationships are greatly stronger for items that had lower percentages of uncodable remarks (r2 = 0.93, p < .05),20 thereby confirming the suspicion that coding error has contributed significantly to the weaker than expected relationships depicted in Table 4.6. Inspection of Figure 4.2 provides one additional bit of information. There were many more uncodable remarks associated with the stop-and-think probes (lower right) than with the retrospective probes.21 This would seem the most likely reason why the consistency effects from the stop-and-think probes are so much weaker in Table 4.6 than the effects from the retrospective probes.22 Within the limits inherent in this type of data, then, the results in Table 4.6 are probably about as strong as can be expected. They involve sizable consistency effects at conventional levels of statistical significance in five of six trials, as well as an effect close to significance on the sixth - despite a significant amount of measurement error, a small sample, and abnormally low base rates of instability owing to the short time between reinterviews. These data can be used to make one other point. The measure of consistency of open-ended remarks in Table 4.6 has been calculated over both waves of the survey in order to capture consistency both within and across interviews. The measure can, however, be calculated within a single interview and used to predict response stability on the closed-ended item at the second interview. When this is done, we come up with a strong, clear finding: The one-wave measure has almost no capacity to predict response instability across waves. This suggests that the internal conflict most responsible for response instability is conflict of which respondents themselves are unaware because it occurs across rather than within interviews. Thus, for example, once the vacillating teacher from the introduction to this chapter began to view the government services issue through the prism of "bloated government," she (or he) may have put herself in a mindset that prevented her from thinking about the "education crisis" that had so agitated her in the first interview.23 This suggestion fits nicely with A4, the Response Axiom, which holds that people tend to answer survey questions hastily and on the basis of incomplete memory searches. By virtue of the importance of the phenomenon they purport to explain, the nine deductions concerning the existence and nature of response instability are among the most significant in the book. Most of the empirical findings to which the section refers are well-established; what is new is the explanation given for them. At present, the most widely accepted explanation for response instability is that of Achen (1975). He maintains, as discussed in Chapter 2, that it is due primarily to measurement error. The everyday language used in survey questions is inevitably somewhat vague, and this makes it difficult for people to reliably map the attitudes in their heads into the appropriate response categories. It must be emphasized that nothing in the RAS model is strictly inconsistent with this view. One reason that, as the RAS model claims, individuals so often bring different considerations to the evaluation of the same question may be, exactly as Achen contends, that most questions are open to multiple interpretations.24 In other words, both the measurement error and the RAS models agree that response instability occurs because ordinary language is rarely precise enough to force individuals to think about an issue in the same way every time they confront it. Two examples may serve both to underscore and clarify this point. Consider a person who vacillates on whether the government should "guarantee each person a job and a good standard of living." It is easy to imagine that, as the RAS model would suggest, this vacillation depends on whether the person thinks about the issue in terms of the government's responsibility to maintain a "full-employment economy" (which most people favor), or in terms of a Swedish-style welfare state (which most oppose). But it would certainly also be reasonable to attribute such vacillation to question vagueness, since the question can readily be criticized as both double-barreled and unclear. Now consider this example: A person vacillates over whether ''defense spending" should be increased or decreased. One might, in the spirit of the RAS model, imagine that the respondent is ambivalent between fear of foreign enemies, on one hand, and anger at Pentagon waste, on the other. In the measurement error tradition, one would instead contend that the stimulus is vague (what exactly is meant by ' 'defense spending"?). Thus, both theoretical approaches can, at least in a technical sense, handle quite different cases of response instability, one of which involves a question that is easily criticized as vague and the other of which involves a question that is, by the standards of survey research, quite clear and direct. There is, however, a fundamental difference between the two models. In the measurement error tradition, response error is simply so much noise. It has no substance and signifies nothing of interest about the nature of mass opinion. Insofar as we learn anything of theoretical significance from it, we learn about the vagueness of natural language rather than the nature of public opinion. In the RAS model, by contrast, response variation is rooted in an important substantive phenomenon, namely the common existence of ambivalence in people's reactions to issues. This ambivalence has numerous implications, as we shall see as the book progresses, for such matters as the priming effect of the mass media, the effects of survey question order, and attitude change. The RAS model's account of response instability, thus, is an integral part of a much more comprehensive way of thinking about public opinion.

# Chapter 7: Basic processes of "attitude change"

Within the RAS model,' 'attitudes,'' in the conventional sense of the term, do not exist. Rather, people make ''attitude reports" or "survey responses" on the basis of momentarily salient considerations. Attitude change, then, cannot be understood within the RAS model as a conversion experience, the replacement of one crystallized opinion structure by another. It must instead be understood as a change in the balance of positive and negative considerations relating to a given issue. To model it, one must represent the process by which new considerations are added to the pool of existing considerations in the person's mind, thereby permanently altering long-term response probabilities on the issue. Permanent alterations in long-term response probabilities are the RAS model's equivalent of attitude change. Since this phrase is a cumbersome one, my discussion of the phenomenon will retain the more standard locution, attitude change. However, the reader should keep in mind that I am using it as a phrase of convenience, and am actually referring to an alteration in long-term response probabilities that has been brought about by the acquisition of new considerations. Attitude change, understood in this way, makes an enormously more interesting subject of study than cross-sectional opinion. When adequate opinion data are available, as they are in a handful of cases, the analyst is no longer forced to infer a dynamic process from a static distribution of opinion, as was done in Chapter 6, but can directly observe the processes that are shaping opinion. This permits a more challenging and stimulating test of the RAS model than has been possible so far. It will, in particular, enable us to see in detail whether the effects of exposure to streams of opposing information flows, are, as claimed, major forces in shaping mass attitudes. This chapter deals with the basics of attitude change, including some initial tests of the argument. More demanding and revealing tests of the model appear in later chapters. Although I will continue to use the RAS model in this chapter to deduce expected patterns in the data, the deductions will be fewer and easier to keep track of. Hence, I will cease numbering them as in earlier chapters. 

## MODELING ATTITUDE CHANGE 

The defining axioms of the RAS model have strong implications for how attitude change, as just defined, may be expected to occur. To develop these implications, we return to the fundamentals of the model.

Suppose that, after some interval of time, public opinion on a certain issue has changed. From the perspective of the RAS model, such change can only have occurred because the relative salience of liberal and conservative considerations in people's minds is different from what it was previously; this, in turn, may have come about by one of only two routes. The first is that recent events or information may have increased the salience of preexisting liberal or conservative considerations, thereby bringing about changes in people's attitude reports, as discussed under the rubric of salience effects in Chapter 5. Although salience effects may persist for any period of time, depending on how long the events or information causing them remain current, they involve no changes in people's feelings toward the issue itself and hence do not fit the definition of attitude change. Salience effects that persist may be more appropriately described as "mood changes." Mood changes may be difficult to distinguish empirically from attitude change, except in a laboratory experiment that alters a person's general state of mind without exposing her to any new ideas. Nonetheless, I conjecture that the well-known presidential "rally-round-the-flag effects," whereby the job performance ratings of U.S. presidents shoot up in times of international crisis (Mueller, 1973; Brody, 1991), may be partially due to mood shifts in the public. That is, the public may lay greater stress on the president's leadership function in times of threat, and evaluate him differently even though the considerations underlying the evaluations are unchanged. However, I stress that shifts in the national mood can be, at most, only a partial explanation for rally effects, since, as Brody (1991) has shown, the timing and magnitude of rallies is dependent on the extent to which other political elites support the president in time of crisis. Owing to the lack of data, I shall have nothing further to say about mood effects in this study. The other way in which the RAS model allows changes in the public's response to an issue is as follows: Some members of the public have been exposed to persuasive communications and accepted them as considerations, thereby altering the balance of liberal and conservative considerations in their minds and hence their long-term response probabilities. This type of change fits the definition of attitude change, as given a moment ago. Attitude change, thus, depends on a two-step process involving reception of new ideas and acceptance of some as new considerations, thereby altering the balance of considerations in people's minds. Note that people may form both new liberal and new conservative considerations during a period of attitude change. All that is logically required for attitude change to occur is that, if overall opinion has moved, say, in a conservative direction, the relative prevalence of conservative considerations in people's minds has increased. If, as ought normally to be the case, the initially existing balance of considerations reflects the balance of competing conservative and liberal messages in the preceding period, the relative prevalence of conservative considerations will increase if the relative intensity of the conservative message has increased. To take an example: Suppose that, every week, the news media broadcast nine liberal stories on a given issue and one conservative story, each having equal prominence and credibility. Then suppose the media begin broadcasting eight liberal and two conservative messages every week. This would count as a gain in the relative intensity of the conservative message and would create a movement of opinion in the conservative direction. It is helpful at this point to drop references to liberal and conservative messages and to recast the argument in terms of dominant and countervailing messages. Thus, the message that is more intense during the period of attitude change is defined as the dominant message, and the less intense message is the countervailing message. Opinion change may sometimes occur in the direction of the countervailing, or less intense, message if the less intense message, though remaining less intense, has nonetheless gained in relative intensity (as in the example in the preceding paragraph). Most often, however, opinion change probably runs in the direction of the more intense or dominant message. Let us say that the probability a given individual will express support for the dominant position at time 1 is1 C, + D, where C, and Dx are the number of considerations in the person's mind initially favoring the countervailing and dominant positions, respectively. So if some individual has three dominant and two countervalent considerations, and if she responds to survey questions on the basis of the first consideration that comes to mind, the probability of stating a dominant opinion is 3 / (3 + 2) = .6. Over the next time period, persons may, in response to the political communications they encounter, form new considerations. New considerations favoring the dominant message will be designated D2, and new considerations favoring the countervailing position will be C2. Given this, change in long-term response probability - that is, "attitude change" - can be specified as the difference between the proportion of considerations favoring the dominant position at time 2, and the proportion favoring this position at time 1, as follows: Change in response probability = V«-l ">" ^2) "T \*S\ r LSI) (7.1) (C, + C2) + (D, + D2) C, + D, This equation, which simply claims that changes in long-term response probabilities depend on changes in the mix of considerations relating to an issue, is the foundation for all of this study's subsequent investigation of attitude change. From Equation 7.1, we can see that the incidence of attitude change in response to dominant and countervailing messages depends on four quantities: C,, D,, C2, and D2. In beginning to think about the incidence of attitude change, it is useful to focus on resistance to change in the direction of a dominant message, given exposure to dominant and countervalent messages. Such resistance can take three forms, which I will describe as partisan resistance, inertial resistance, and countervalent resistance. Each depends on one or more of the terms in Equation 7.1, as follows: Partisan resistance. Individuals may refuse to internalize new dominant messages that they recognize as inconsistent with their underlying predispositions, where such recognition depends (via axioms A1-A3) on the possession and accessibility of contextual information from a relevant cueing message. By rejecting dominant messages, persons ensure that D2 is a small number or perhaps zero, which reduces change in the direction of the dominant message. Because such outright rejection of the dominant message is rooted in a person's predispositions, I refer to it as predispositional or partisan resistance. Inertial resistance. Individuals, especially well-informed ones, may possess large stores of preexisting considerations, Cx and D,, so that even if some new considerations, D2, are internalized, their effects will be swamped by the effects of previously formed considerations. Because this form of resistance depends on the inertial mass of preexisting considerations, I refer to it as inertial resistance to persuasion. Countervalent resistance. Individuals may internalize countervalent considerations, C2, during the period of attitude change. The effect of these considerations in counteracting newly formed dominant considerations is what I call countervalent resistance. It follows from the logic of the RAS model that the incidence of each type of resistance is likely to increase with increasing levels of political awareness. To see why this is so, we can consider the example of how liberals would be affected by a dominant conservative message and a countervailing liberal message. Obviously, liberals will be more likely than conservatives to reject the dominant conservative message - if they possess the contextual information that enables them to recognize it as inconsistent with their predispositions. Because more aware liberals will, by the Reception Axiom, be more likely to possess the contextual information necessary to achieve such recognition, they will be more likely to reject the dominant messages which they receive, thereby exhibiting greater partisan resistance than less aware liberals. The most politically aware liberals will also tend to have the largest stores of existing liberal considerations, thereby making them most likely to exhibit inertial resistance. The reason is that, as highly aware persons, they will have been more heavily exposed to liberal messages previously, and, as liberals, they will likely have internalized many of them as considerations. Finally, highly aware liberals will be most heavily exposed to the countervailing liberal message during the period of attitude change and, as liberals, they will be likely to accept it. Hence they will be most likely to internalize new liberal considerations, thereby exhibiting countervalent resistance to change. Note that, in this example and throughout my discussion of attitude change, resistance to change means resistance to change in long-term response probabilities. Thus, the highly aware may internalize some conservative messages but yet, because they also form some new countervalent considerations or exhibit inertial resistance, remain unchanged in their long-term probability of giving a conservative response. More generally, resistance to a dominant communication flow can take quite different forms. People may resist either by rejecting uncongenial messages at the point of encountering them, or, if some are accepted, by counteracting the effects of the dominant messages by means of countervalent and inertial considerations. Since each of the three forms of resistance to persuasion produces distinctive effects, it will be possible to demonstrate that each makes an independent contribution to resistance to attitude change. Chapters 8 through 10 develop the evidence of these independent resistance effects. This chapter, however, takes a different tack. It will develop a model of attitude change that makes no direct reference to any of the three resistance mechanisms, and no direct reference to countervalent communications. It will be, therefore, a 44one-message" model of attitude change, where the one message is the one that is gaining in relative intensity and thereby bringing about attitude change. The one-message model will serve to introduce the reader to the complex patterns of attitude change that can be expected within the RAS model; it will also be capable of functioning as a sort of "reduced form" model of attitude change in the majority of situations in which the data necessary to observe the independent effects of inertial, countervalent, and partisan resistance are unavailable.

## A RECEPTION-ACCEPTANCE MODEL OF ATTITUDE CHANGE

From the preceding discussion, attitude change requires, at a minimum, reception and acceptance of one or more new considerations. Accordingly, I will represent attitude change as the outcome of the following probabilistic receptionacceptance process: Prob(Change) = Prob(Reception) x Prob(Acceptance I Reception) (7.2) where Prob(Change) = probability of change in long-term response probability Prob(Reception) = probability of reception of a change-inducing message; by reception is meant that the person has been exposed to and comprehended the message Prob(Acceptance I Reception) = probability of accepting (or internalizing) the message, given reception Thus if, for example, an individual has a .5 probability of receiving a message and a .5 probability of accepting it (having received it), his probability of attitude change, according to this model, is simply the product of these reception and acceptance probabilities, that is, .5 x .5 = .25. As is obvious, this formulation of the attitude change process omits any reference to ''considerations," which cannot be easily measured in most attitude change situations, and refers instead to the probability of change in a person's summary attitude report. It also omits any reference to countervalent messages, even though they will often be present in attitude change situations. These are significant simplifications. Yet, Equation 7.2 does depict a reception-acceptance process, as required by the RAS model, and the equation can, as we shall see, be filled out in a way that implicitly accommodates the effects of both considerations and countervalent messages on the incidence of attitude change. Let us begin filling out Equation 7.2 by more fully specifying the reception and acceptance functions that jointly constitute it. From previous chapters, we know that the probability of reception of change-inducing messages is positively associated with a person's level of general political awareness. Thus we can stipulate that Prob (Reception) in Equation 7.2 is an increasing (positive) function of political awareness. With respect to the acceptance function in Equation 7.2, we know from the previous section that - owing to their greater attention to cueing messages, their larger stores of considerations and their greater exposure to countervalent messages - more aware persons are relatively more resistant to the effects of dominant messages that are inconsistent with their predispositions. We can therefore use awareness, a measured variable, to capture the effects of these three difficult-to-observe resistance mechanisms. More specifically, we can specify an acceptance function for Equation 7.2 in which acceptance rates decline as awareness and ideological distance from the message jointly increase. Before completing specification of the reception and acceptance functions, it will be useful to provide illustrations of the ideas developed so far and to sketch their principal implications. Consider the following hypothetical data, which give probabilities of reception, acceptance, and attitude change for persons having different levels of political awareness: Attitude change in response to a hypothetical message Level of awareness Lo^ Prob( Reception) Prob(Accept I Reception) Change (Reception x Acceptance) In the first row, reception probabilities increase from .10 to .50 to .90 as political awareness increases from low to middle to high. These numbers capture the notion, central to the RAS model, that reception increases with awareness. In the second row, acceptance probabilities decrease from .90 to .10 as awareness increases from low to high. These hypothetical numbers capture the notion, developed in the preceding section, that acceptance levels tend to decline with increases in awareness. The resulting change probabilities, which are formed by multiplying reception rates by acceptance rates within each column, are shown in the third row. As can be seen, persons in the middle levels of awareness are most likely to experience attitude change in this hypothetical case. Thus, the model implies that the relationship between awareness and attitude change may be nonmonotonic, that is, that persons at middle levels of awareness may be most likely to change. As was indicated in the brief discussion of congressional elections in Chapter 2, and as much more evidence will attest, nonmonotonic patterns of attitude change turn up with considerable regularity in opinion data. Hence, Equation 7.2, with further elaboration of the reception and acceptance functions, will be central to the explanation of attitude change over the next four chapters. It must immediately be added, however, that attitude change does not always conform to a nonmonotonic pattern. Markedly different patterns of change are expected, depending on how various message-level and individual-level factors interact. Thus, a nonmonotonic pattern of attitude change is simply one special case among many possibilities. These different possibilities do not occur at random but adhere to a definite theoretical model. This point is best made by reviewing the work of William McGuire (1968, 1969), the social psychologist who first proposed a reception-acceptance model of attitude change having the form of Equation 7.2.

## PATTERNS OF ATTITUDE CHANGE

McGuire began with a problem that had long vexed social psychologists, namely the relation between personality and persuasibility. McGuire noted that several personality traits - self-esteem, intelligence, and freedom from anxiety - had been shown to be associated with nonmonotonic patterns of attitude change in experimental studies of persuasion in laboratory settings. To explain this occurrence, he suggested that these personality traits might be positively associated with reception of persuasive communications but negatively associated with disposition toward acceptance, given reception.2 In the case of the expected positive relationship between self-esteem and reception, for example, one might argue that high self-esteem is associated with low need for ego defense, greater capacity for focusing one's attention, and lower levels of anxiety - all of which conduce toward a higher probability of reception of persuasive communication.3 As regards the expected negative relationship between self-esteem and acceptance of the communications which one has received, one could argue that people possessing little self-esteem tend to yield uncritically to whatever communications they happen to encounter. Having thus posited that self-esteem has a positive relationship with reception and a negative relationship with acceptance, McGuire proposed the logic of the reception-acceptance process, as embodied in Equation 7.2 and illustrated in the hypothetical data just examined, to explain why the expected relation between self-esteem and attitude change is, under certain conditions, nonmonotonic. McGuire goes on, however, to show that Equation 7.2 can account for a variety of other patterns of opinion change. In fact, the great value of the reception-acceptance model proposed by McGuire is that it enables the analyst to explain results that seem at first to be contradictory. Consider a typical "hard learning" situation, which is defined as a situation in which the persuasive message is, for some reason, difficult to receive. The factors making for difficulty of reception might include background noise, the presence of distractions, or the inherent difficulty of the message. A prototypical hard learning situation is a college lecture in physics. All physics students may be presumed to have a high disposition toward acceptance of the contents of the lecture, but only the most intelligent may be able to understand it. One can capture this situation by saying that everyone has a 1.0 probability of accepting the contents of the physics lecture, given reception of it. But effective reception of the physics lecture will be positively correlated with intelligence. When we represent these ideas in a reception-acceptance table, like the one following, we find (in the bottom row of the table) that the most intelligent students are most likely to undergo "attitude change" in response to the instructor's "persuasive argument." Attitude change in a "hard learning" situation Levels of intelligence Low Middle High Prob(Reception) .10 .20 .30 Prob(Accept I Reception) 1.0 1.0 1.0 Change (Reception x Acceptance) .10 .20 .30 As will be seen below, there are also political situations in which messages have so little intensity, or are so difficult to comprehend, that, like some physics lectures, they reach only the most aware persons. In such cases, which might also be called "hard learning" situations, the most aware persons are most likely to change. Although generally resistant to persuasion, they are the only people who will have been effectively exposed to any new information. Now consider an entirely different kind of persuasion situation, an "easy learning" situation in which someone stands in front of a large audience and repeats suggestively, "Your head is moving back and forth, back and forth." What makes this an easy learning situation is that the persuasive message is so extremely simple and clear that we may assume that essentially everyone, except perhaps the hard of hearing, receives it. To capture the dynamics of such an easy learning situation, we set everyone's reception probability to 1.0. If, as shown below, we assume that acceptance probabilities in this situation would be negatively correlated with intelligence, and then carry out the multiplication of rows in accord with the model, we find that people with the least intelligence should be most likely to begin swaying their heads back and forth. Attitude change in an "easy learning" situation Levels of intelligence Low Middle High Prob( Reception) Prob(Accept 1 Reception) Change (Reception x Acceptance) 1.0 .90 .90 1.0 .50 .50 1.0 .10 .10 McGuire cites numerous studies whose results, though once apparently contradictory, make sense when interpreted in light of this model. For any individual trait variable that is positively correlated with reception of persuasive communications and negatively correlated with likelihood of uncritically accepting them, the relation between the trait and attitude change can be positive, negative, or nonmonotonic, depending on whether the persuasion situation stresses the capacity of subjects to receive the message (as in the educational or 4'hard learning" situations), their willingness to accept the message (as in the case of the easy but repetitious message), or both (which may sometimes produce a nonmonotonic pattern of change). Political awareness, like the personality traits that McGuire examined, would be expected to be positively correlated with reception of persuasive communications and negatively correlated with likelihood of uncritical acceptance. Hence, the relation between awareness and attitude change may be positive, negative, or nonmonotonic. In fact, whole families of curves can be generated in theory and matched to actual data, depending on how an individual's predispositions and awareness interact with particular messages. What gives rise tofamilies of curves, rather than a single curve pattern, is that persuasive communications vary continuously from very hard (or "low intensity") to very easy ("high intensity"), and as message intensity changes, the shapes of the attitude change curves generated by the messages change incrementally. Similarly, resistance to a message may differ incrementally in different groups, depending on the fit between their partisanship and the partisan coloration of the message source. This was a type of factor that McGuire did not consider, but it can greatly affect the shape of the attitude change curves that one observes. Let me offer some illustrations. The following set of tables illustrates how patterns of reception and acceptance of a liberal message among three ideological groups - liberals, centrists, and conservatives - might come together to form a family of attitude change curves: Within all three groups, reception of the liberal message increases from . 10 to .50 to .90 as political awareness increases; this is shown in the top row of each part of the table and indicates that the intensity of the persuasive message is the same for all three groups. Also within all groups, acceptance rates decline with awareness. Yet the decline in acceptance rates is much steeper for conservatives (where it falls from .90 to .02) than among liberals (where it declines only from .90 to .80), with centrists falling in between. The result is that attitude change is expected to follow different patterns in the two groups: Change rises with awareness among liberals (from .09 to .425 to .72) but is nonmonotonic with respect to awareness among centrists and conservatives. Because these patterns reappear in various guises throughout the rest of the book, generally resembling actual estimates of reception and acceptance rates, as shown in Figures 7.4 and 10.1, it is essential for the reader to be entirely clear about how the nonmonotonicity comes about: Conservatives and centrists having low levels of awareness do not change much because only 10 percent of them are ever exposed to any change-inducing messages. Highly aware conservatives and centrists are very likely to be exposed to the liberal message (their reception rate is 90 percent), but their acceptance rates are so low (2 and 20 percent, respectively) that few end up changing their attitudes. This leaves moderately aware conservatives and centrists most susceptible to change: They pay enough attention to be likely to receive the liberal message but are not sufficiently aware to be able to reject it as inconsistent with their values. The shapes of the nonmonotonic change curves among conservatives are, as can be seen, somewhat different than among centrists, because the negative effect of awareness on acceptance is stronger in the former case than in the latter. A question that arises in this example is why, among liberals, there is any tendency for awareness to create resistance to persuasion by a liberal message. Indeed, might not acceptance rates rise with political awareness when the message is a congenial one? My answer to this question is empirical: When a model is designed to allow for this sort of interaction, there turns out always to be a negative relation between awareness and probability of acceptance, even when the message is ideologically congenial. The effect of awareness on acceptance may be slight, as in this example of liberals responding to a liberal message, but it seems always to be negative.4 What this indicates is that, perhaps for reasons of inertial resistance, more aware persons are always somewhat more resistant to change, given reception of a change-inducing message, than are less aware persons.

## INITIAL TESTS OF THE MODEL

Even though development of the abbreviated reception-acceptance model is not yet complete, it is useful to demonstrate that the simulations just outlined resemble cases of attitude change that actually occur in the political world. I will take two such cases, one involving opinion change in a liberal direction and the other change in a conservative direction. The first case involves public attitudes toward defense spending. In the 1980 and 1982 election studies, the NES asked the following question: Some people believe we should spend much less money for defense. Others feel that defense spending should be greatly increased. Where do you stand on this issue, or haven't you thought much about it? Respondents were then asked to place themselves on a seven-point scale, from greatly reduced spending at point 1 to greatly increased spending at point 7. During the two-year interval between surveys, coverage of the defense issue in the press was heavily unfavorable toward defense spending. As discussed in Chapter 2, a content analysis of stories in Newsweek found that stories favoring cuts in spending outnumbered pro-spending stories by a ratio of about 2 to 1. Thus, although countervalent communications were present, there was a dominant, anti-defense-spending message in this period. Presumably as a result of this dominant message, the percentage of persons favoring cuts in defense (persons who took point 1, 2, or 3 on the defense scale) in the two NES surveys rose from 10 percent to 28 percent.5 The second example involves U.S. policy in Central America. The question, which was asked in the fall of 1986 and again to a subsample of the same respondents in June 1987, was as follows: Some people feel that the United States should become much more involved in the internal affairs of Central America. Others feel we should become much less involved. Where do you stand on this issue, or haven't you thought much about it? The Iran-Contra controversy emerged in November, as the National Election Study went into the field, and hit full stride over the next few months. At the heart of the controversy were allegations that the Reagan administration had illegally used funds from the sale of weapons to Iran to support the Contra guerrillas, who were fighting to overthrow the communist government of Nicaragua. The Senate's Iran-Contra hearings were under way at the time of the reinterview in June. As we will see in the next chapter, this controversy brought a steep decline in President Reagan's popularity. But it also brought increased publicity to the President's Central America policy, as exemplified in the defiant testimony of Lieutenant Colonel Oliver North at the Senate Contra hearings. The result was increased public support for American involvement in Central America. In the 1986-7 NES surveys, the increase was from 28 percent support to 38 percent support.6 Given that mass attitude change has occurred, the reception-acceptance model gives us definite expectations concerning the patterns of the change. When opinion changes in response to a predominantly liberal message, as in the case of defense spending, we expect that, for liberals, there will be a positive relation between political awareness and likelihood of change, as in the preceding example. For conservatives responding to a liberal message, we expect a nonmonotonic pattern in which moderately aware conservatives are most likely to change, as also indicated in the preceding. But when, as in the Central America issue, mass attitude change occurs in response to a conservative message, our expectations for liberals and conservatives reverse: We anticipate a positive relation between awareness and change among conservatives, and a nonmonotonic relation with awareness among liberals. To test these expectations, we need, for each survey, a measure of political awareness and a measure of individuals' values or partisanship. Awareness can be readily measured in both surveys with tests of neutral political knowledge. For the surveys capturing attitude change on Central America, an excellent measure of political values is available, namely, the Hurwitz-Peffley items on anticommunism and military vigilance (Hurwitz and Peffley, 1988).7 For the 1980-2 surveys, the most appropriate measure of values carried on both surveys is the traditional measure of party attachment. Since differences between Democrats and Republicans on defense spending were one of the major elements of interparty conflict in the early 1980s, party attachment is a reasonable measure of individual predispositions on this issue. The results of the tests are shown in Tables 7.1. and 7.2.8 Let us look first at Table 7.1, which deals with the defense spending issue. The table shows rates of support for cuts in defense spending, separately in 1980 and 1982, for Democrats and Republicans by level of political awareness. Thus, it can be seen that in 1980, 12 percent of Democrats in the lowest awareness category favored cuts in defense spending; but in 1982, 16 percent of Democrats in the low-awareness category favored such cuts. This amounts to a difference of 4 percentage points. Meanwhile, the most highly aware Democrats went from 20 percent in favor of defense cuts to 57 percent in favor, a difference of 37 percentage points. Our interest here is in the probabilities of attitude change, that is, the probability that a person not already committed to cuts in defense spending would switch to favor such cuts in the second survey. Thus if 20 percent of highly aware Democrats favored cuts in 1980 and 57 percent did so in 1982, then the percentage of persons not initially favoring cuts who switched was _ [Time2 - Timei] [57% - 20%] Percent change = [100% _ ^ = [100% - 20%] = 46% Change rates, calculated in this way for Democrats at each level of awareness, are displayed in the third row of Table 7.1. As can be seen, they generally fit expectations: More aware Democrats are more likely to have switched to a position of favoring defense cuts. The lower panel of the table provides parallel data for Republicans. Note the change figures for Republicans in the bottom row of the table; as can be seen, change levels run from 2 percent in the lowest awareness category to 13 percent in the next category to 27 percent in the third category and then down to 10 percent in the highest category, a relationship that is, as expected, nonmonotonic. Altogether, then, the results from the defense spending issue conform well to theory. Table 7.2 presents comparable data for the Central American issue. The fit to expectations here is fairly good but, at least at first glance, not perfect. Among 4'hawks" there is a positive relationship between political awareness and change in the direction of greater support for American involvement in Central America. Among "centrists" this relationship is sharply nonmonotonic, a result that is quite in the spirit of the model. There is, however, a problem with the "doves." As would be expected, doves were much less responsive to the pro-Contra message than were either hawks or centrists. But contrary to expectation, the tiny handful of doves who did move in a conservative direction were not moderately aware doves, but very highly aware doves. This departure from expectation is more apparent than real. For one thing, the number of cases in the critical cells is such that small departures from expectations should not be taken too seriously.9 (Different responses by just two individuals in the cell for highly aware doves would have brought the change rate in this group down to .04.) Table 7.2 also shows the effect of only one predispositional variable; there may be other predispositions that need to be controlled before we can get a clear picture of how attitudes were changing. The need for controls and statistical tests highlights the limitations of tabular analysis for testing the RAS model. To address these needs, it is necessary to develop a statistical model of the attitude change process. Since variants of this model will be at the center of my analysis in the remainder of the book, I will fully describe each step of the model development. This will involve detail that statistically accomplished readers may find tedious, but that others will, I hope, find useful. A STATISTICAL MODEL OF ATTITUDE CHANGE The basis of the statistical model will be Equation 7.2, repeated below: Prob(Change) = Prob(Reception) x Prob(Acceptance I Reception) Attitude change, thus, is a multiplicative function of separate reception and acceptance functions. To make this equation a statistical model of attitude change, we need to specify the nature of these reception and acceptance functions. From earlier discussions, we have a fair amount of information about what these specifications must be. We know, first of all, that political awareness is positively associated with reception of persuasive communications, and we know that awareness and political values (and perhaps other variables) are negatively associated with the likelihood of uncritical acceptance. But to make full use of this information, we must know the functional form of the relationships between these independent variables, on one side, and the dependent variables, reception and acceptance, on the other. We need to know, in other words, whether the form of these relationships is strictly linear, exponential, or something else. If this seems an arcane issue, consider the following problem. Suppose that we have tested several million schoolchildren from kindergarten through grade twelve on the question, "What is the square root of 4?" And suppose that we now want to model the relationship between years of schooling and the probability of getting the correct answer to this question. Obviously, we would expect to find a positive relationship. That is, more years of schooling would be associated with a higher chance of getting the answer right. But as Figure 7.1 shows, there are several forms this relationship could take. The top panel depicts a strictly linear relationship: Each additional year of school increases the probability of a correct response by a constant amount. The middle panel depicts an exponential relationship: Schooling affects knowledge of square roots slowly at first, but has an increasingly powerful effect as one goes further in school. Thus going from the first to the second grade has scarcely any effect, but going from eleventh to twelfth grade has a very large effect. The bottom panel of Figure 7.1 claims that the relationship between schooling and math knowledge follows the form of a logistic function: The earliest and latest years of school have little effect, but the middle years of school have a substantial effect. The point here is that in order to model the relationship between two variables, one must know more than just the fact that they are positively correlated. One must know - or at least be able to make a plausible guess about - the form of their relationship. To resolve this problem in the present example, we would use our background knowledge of how education is organized in the United States. Knowing, that is, that square roots are normally taught between the third and eighth grades, we would assume that little learning about square roots occurs in the very early or very late years of school, and hence that the logistic functional form best describes the relationship between years of school and correct answers on this particular test question. The choice of functional form in the case of awareness and reception is also fairly clear. Since we are dealing with probabilities of reception, we would like to have a function that varies naturally between 0 and 1. The logistic form meets that requirement. The lowest value it can take is 0 and the largest value is 1. Empirical studies of the diffusion of ideas also often find that logistic functions (or close equivalents) provide a good fit to the actual data (Price, 1961; Neuman, 1990).10 For all these reasons, I will assume that the relationship between awareness and reception can be represented by the following logistic function: Prob(Reception)/ = 1 - [t +y+ g(«, + a, Awareness,)] (7-3) where Prob(Reception)i = the probability that individual (/) will receive a persuasive message a0 = coefficient designating the intensity of message ax = coefficient designating strength of relationship between awareness and reception / = floor parameter e = the natural logarithmetic base, 2.7214 Equation 7.3 can be equivalently written as Prob(Reception), = 1 - [1 +/ + Exp(a0 + #iAwareness,)]~! (7.3') Since many readers will not be greatly familiar with this type of logistic function, and since it will be heavily and somewhat unconventionally used in my examination of attitude change, it is worth digressing to gain some familiarity with the function and its associated parameters. The "tf i" parameter is, first of all, a measure of the strength of the relationship between political awareness and reception of a particular message. Thus, it is the analogue of the slope in a standard linear regression. The top panel of Figure 7.2 shows how the relationship between awareness and reception varies for a typical range of values of ax: (ax = .5, ax = 1.0, a, = 2.0).n The higher the value of a,, the stronger the relationship between awareness and reception. For the case in which ax = 2.0, reception levels are near zero at low awareness, begin a sharp rise at about -2, and approach a ceiling of 100 percent by the time awareness reaches a level of +2 units. Political awareness in Figure 7.2 has been scored in standard units. The measures of political awareness that I will use in modeling attitude change have also been expressed in standard units. Since the awareness measures usually have a roughly normal distribution, this means about 96 percent of individuals will usually have awareness scores that fall within an interval of ±2 units on Figure 7.2. Knowing this, the reader can interpret the magnitude of the coefficients reported in later sections of this book by referring back to Figure 7.2. For example, for a case in which the awareness coefficient is 1.0 and a0 is near zero, Figure 7.2 implies that reception levels rise from about 10 percent at low levels of awareness to 90 percent at high levels of awareness. Relationships of this strength or greater will be common in the empirical analyses reported below. The a0 parameter captures the difficulty or the "loudness" of the particular message, and is the analogue of the intercept in standard regression. The middle section of Figure 7.2 shows how reception varies with information at three different values of a0 (and a fixed value of ax = 2.0). High values of a0 indicate high levels of reception at given levels of awareness, which in turn indicate 4'high-intensity" messages. If appropriate care is taken in the construction of variables, the a0 coefficients can be compared across models to see which involve the most intense message. This brings us to the /parameter. All of the projections in the top and middle panels of Figure 7.2 set the floor parameter,/, to zero. When/takes on positive values, it sets minimum or "floor" levels of reception, regardless of an individual's level of awareness. The bottom panel of Figure 7.2 shows three reception curves that are identical to those in the middle panel, except that the floor parameter is set to .30. Thus, instead of rising from a floor of zero, reception rises from a floor determined by f. Floor parameters are necessary in situations in which people may respond to survey questions without having received any information about the question which, in many cases, probably means guessing. Without a floor parameter to assign ''reception" scores to guessers, the model I am developing would have no way of accommodating the fact that such persons give answers to survey questions. The/parameter, thus, is a nuisance term that improves the fit of the model to the data without conveying substantive significance. As Figure 7.2 shows, it has an effect only at lower levels of awareness, where guessing is likely to be most common.13 The probability that an individual will accept a persuasive message (having received it) decreases with awareness and ideological distance from the message. Again assuming that the logistic function describes the form of this relationship, we may write Prob(Accept I Reception), = [1 + Exp(-Z?0 ~~ &iAwareness, - ^Predispositions, . . . )]-1 (7.4) where Prob(Acceptance I Reception), = the probability that individual (/) will accept the persuasive message, having received it b0 = coefficient designating the difficulty or credibility of message bx = coefficient designating the effect of awareness on resistance to persuasion b2 = coefficient designating the effect of predispositions on resistance to persuasion Equation 7.4 differs from Equation 7.3 in two important ways. First, its form has been altered so as to make its coefficients more intelligible. In particular, Equation 7.4 has been set up so that if, as expected, higher levels of awareness are associated with lower acceptance rates, the coefficient on awareness will take a negative sign.14 The second difference is that the acceptance function contains a term for differences in political predispositions, that is, ideology, party, religiosity, or whatever. An important feature of logistic functions is that whenever two or more variables are used, the variables automatically interact with one another - which is to say, the effect of one variable depends on the values taken by the others. Thus, in Equation 7.4, the effect of awareness will always depend on the effect of the predispositions variable(s). It is necessary to allow for such Awareness x Predispositions interactions because the RAS model holds that predispositions have no effect unless the individual is sufficiently politically aware to possess the contextual information that enables resistance to uncongenial messages. Thus, as we saw in Table 7.1, unaware Democrats and Republicans did not differ much in their resistance to anti-defense-spending communications: The former became 4 percent less favorable toward defense spending, while the latter became 2 percent less favorable. Yet party attachment had a large impact on resistance to antidefense messages among highly aware partisans: Democrats became 46 percent less favorable and Republicans 10 percent less favorable. The same sort of Predisposition x Awareness interaction arose, mutatis mutandis, for hawks and doves in response to a conservative message, as shown in Table 7.2. Figure 7.3 shows how Equation 7.4 handles Awareness x Predisposition interactions. In this figure, b0 is set to +2, bx is set to — 1, and b2 is set to -1; party is scored —2 for Republicans and +2 for Democrats. These values, as will be seen below, fall within the range of the values obtained empirically from the application of Equation 7.4 to actual data. The figure shows that increases in awareness lead to lower acceptance rates among both Democrats and Republicans, but to a much steeper decline among Democrats. Thus, the effect of awareness on acceptance depends on whether the person is a Democrat or Republican. (This interaction would occur only when the change-inducing message was a conservative message; for a liberal message, the sign on b2 would reverse, thereby causing awareness to have a greater effect on the acceptance rates of Republicans.) The reader may wonder why, since the RAS model expects this type of interaction, I do not simply include a specific term for Awareness x Predispositions in Equation 7.4. The reason is practical: Most of the time such interaction terms contribute little or nothing to the fit of the model but nonetheless introduce large amounts of troublesome multicollinearity. Or, to put it differently, Equation 7.4 normally picks up interaction effects without the need for specific interaction terms (see Table 7.3). However, in one case, reported in Chapter 9, I found interaction terms helpful and so did include them in an acceptance function. I would, incidentally, encourage readers who have access to a spreadsheet program to replicate the results in Figures 7.2 and 7.3, to experiment with other parameter values, and to plot the results of the more complex functions I shall report here. Doing this will greatly enhance understanding of the claims I make on behalf of the RAS model. We are now ready to bring the reception and acceptance functions together. Substituting Equations 7.3 and 7.4 into Equation 7.2, we get Prob(Change) = (1 - (1 +/ + Exp[+tf0 + «,Awareness])"1) x (1 + Exp[—b0 — b\Awareness - &2Predispositions ...J)"1 (7.5) The first term in Equation 7.5 is a monotonically increasing function of awareness, while the second is a similarly decreasing function of awareness and value distance from the message. There is an important and nonobvious feature of this formulation of the reception-acceptance model. It is the implicit assumption that a person's predispositions, although affecting acceptance of persuasive messages, do not affect reception. This assumption is signaled by the fact that predispositional variables are included only in the acceptance function. This specification of the model would be inappropriate if, as early opinion research indicated, individuals engaged in "selective reception" of political information - if, that is, they exposed themselves mainly to ideas they thought they were likely to find acceptable and avoided exposure to uncongenial ideas. However, more recent research has been unkind to the notion of selective reception (Sears and Freedman, 1967; McGuire, 1969; Wicklund and Brehm, 1976; Cotton, 1985; Patterson and McClure, 1974; Patterson 1980). Most people, this research maintains, are simply not so rigid in their information-seeking behavior that they will expose themselves only to ideas that they find congenial. To the extent selective exposure occurs at all, it appears to do so under special conditions that do not typically arise in situations of mass persuasion.15 The likely reasons for the relative unimportance of selective reception are several. First, most people inform themselves by means of exposure to a fairly wide variety of outlets, most of which are "common carriers" of a national communications flow (Key, 1961). Second, selective reception requires a level of concerned vigilance much greater than most citizens, who are relatively apathetic about politics, are likely to make (Graber, 1984: p. 128). And third, most news events important enough to engage the attention of survey researchers are major, continuing stories such as the Vietnam War or the Iran-Contra scandal, so that people who pay any significant degree of attention to politics are unlikely to remain unaware of them even if they are not avidly interested in each new detail. The selective reception hypothesis cannot be entirely false. After all, it would be extremely surprising if, say, liberal ideologues were as likely to subscribe to National Review as to Nation. But, by the available evidence, selective reception apparently does not occur on a sufficiently broad scale to affect the diffusion of major political ideas, and hence poses little danger to my formulation of the reception-acceptance model.16 Although Equation 7.5 is a model of attitude change, it requires adaptation before it can be applied to the two cases under examination here. There are three reasons for this. The first is that, in the defense spending case, we have no individual-level data on attitude change; rather, we have separate cross-section surveys in which similar individuals, rather than the same individuals, are compared across time. (Thus, for example, the low-awareness Democrats in the 1980 survey in Table 7.1 were not reinterviewed in 1982 to find out whether their attitudes had changed; rather, a separate sample was drawn in 1982 to measure the attitudes of low-awareness Democrats.) From this sort of data one can calculate aggregate-level change rates across different types of persons, as in Table 7.1, but not individual-level change rates of the type required by Equation 7.5. The second limitation of equation 7.5 is that it accommodates change in one direction only - the direction of the dominant message. This creates a problem even when individual-level change data are available, as it is in the Central America case. If, as here, support for a hawkish policy rises from 28 percent to 38 percent, Equation 7.5 implicitly assumes that 10 percent of the sample has changed its attitude in the direction of the dominant message and the other 90 percent has remained stable. Owing, however, to random response variability (see Table 2.1), the actual pattern of change is more complicated. Thus, in the Central America case, 22 percent changed in the direction of the dominant hawkish message while 12 percent changed in a dovish direction, for a net change of 10 percent. Equation 7.5 cannot accommodate such two-way patterns of change. A final difficulty is that if, as in Equation 7.5, one models only individuallevel change rates, one is inefficiently discarding information about the baseline and final distributions of opinion. This information is often essential for gaining leverage on the overall reception-acceptance process. For these reasons, then, we need a model of the attitude change process that is capable of capturing change between a baseline distribution of opinion and a subsequent opinion distribution, and that does so without implicitly assuming that all individual-level change runs in the direction of the dominant persuasive message. One can develop such a model by making separate estimates of baseline attitudes at time, and the probability of attitude change, so that time2 attitudes are a function of baseline attitudes and change probabilities, as follows: Prob(Opinion2) = Prob(Baseline Opinion) + Prob(Change) * (1 — Baseline Opinion) (7.6) That is, the probability of holding a particular opinion at time2 is the probability of holding it at the baseline period, plus the probability of converting to the opinion if not already holding it at time,. The baseline and change functions can be specified straightforwardly as separate reception-acceptance models, each having the form of Equation 7.5. That is, baseline opinion is the outcome of a reception-acceptance process that is captured by Equation 7.5, and attitude change is also the outcome of a receptionacceptance process that is captured by Equation 7.5. This model must be estimated simultaneously on data from both the time, and time2 periods, as follows: Prob(Opinion), = Prob(Baseline) + Dum, * Prob(Change) * (1 - Baseline) (7.7) where Dum, takes the value of 0 at time, and the value of 1 at time2. Thus, opinion at time, depends on the baseline reception-acceptance process only, while opinion at time2 depends on both the baseline and the change models. Since the / parameter in the reception function is intended to pick up the effects of guessing, and since these effects are absorbed in the baseline model, it is unnecessary to include an / parameter in the reception function of the change model. Coefficients from the application of Equation 7.7 to the data on defense spending are shown in the left column of Table 7.3. The dependent variable is a 0-1 variable that distinguishes those who support cuts in defense spending from all others, including those who make no-opinion responses.17 To facilitate replication of these results, I include in the appendix to this chapter the SAS program code used to produce them. The coefficients in Table 7.3 all have good magnitudes, as can be seen by comparing them to the coefficients used to produce Figure 7.2, and signs that run in the theoretically expected directions. However, there is a great deal of statistical imprecision in the coefficients in the acceptance function of the baseline model. The reason for the imprecision in this subfunction appears to be that there is little variance in support for cuts in defense spending in 1980, as can be seen in Table 7.1. To reduce this imprecision, I constrained the value of the most unstable coefficient, that of party, to be equal in both the baseline and change models. This resulted in a more stable set of estimates, as shown in the center column of Table 7.3. The constraint did bring about a statistically significant reduction in the statistical fit of the model to the data (F (1, 2,993), 4.12, p < .05), but did not affect the visual or qualitative fit of the model to the raw data, as shown earlier in Table 7.1. The right-hand column of Table 7.3 shows the coefficients that are obtained when Awareness x Party terms are put into the model. The inclusion of these terms did not significantly improve the statistical fit of the model, and I present them only to satisfy the interest of readers who might wonder about the effect of interaction terms on the performance of the model. There is little more to be learned about the dynamics of attitude change from simple visual inspection of the coefficients from the model. I have, therefore, used the coefficients, in conjunction with Equation 7.7, to construct graphical representations of the implied effects of these coefficients. These graphs, based on coefficients from the unconstrained model and using the graphing conventions set forth in Chapter 6, are shown in Figure 7.4. Figure 7.4 decomposes the attitude change process into its components: reception, acceptance, and attitude change. In the left-hand panel, the figure shows estimated rates of reception of anti-defense-spending messages between 1980 and 1982. These estimates have been obtained by plugging the reception coefficients from the change model in Table 7.3 into the reception function, Equation 7.3, and calculating reception rates at different levels of political awareness. As expected, reception of anti-defense-spending information increases as political awareness increases.18 Acceptance rates, given reception, are shown in the center panels of the figure. They have been obtained by plugging the acceptance coefficients from Table 7.3 into the acceptance function, as given in Equation 7.4. As can be seen, these rates differ markedly for Republicans and Democrats. Among Republicans, political awareness generates much lower rates of acceptance of antidefense information - or alternatively, much higher levels of resistance; among Democrats, awareness also produces higher resistance rates, but only barely so. Thus, as expected, awareness interacts with political predispositions to generate selective resistance to persuasion. Multiplication of the reception rates on the left of Figure 7.4 by the acceptance rates in the center yields estimated rates of attitude change on cuts in defense spending, which are shown on the right. To illustrate how this works, the figure focuses on a hypothetical Republican and Democrat who are somewhat above the median level of political awareness. Each has a 52 percent chance of exposure to antidefense information, but their acceptance rates are quite different: 30 percent for the Republican and 94 percent for the Democrat. Multiplication of these reception and acceptance rates yields attitude change rates, as shown on the right. For the Republican, the change rate is .52 x .30 = .15. These estimated rates of attitude change agree well with the raw data on attitude change, as shown in Table 7.1. Let us turn now to the issue of U.S. involvement in Central America. Coefficient estimates for the application of Equation 7.7 to the data from this issue are shown in Table 7.4. Owing to the much smaller sample involved, these estimates are even less precise than those for the defense spending issue, and here the instability extends to both the baseline and change models. Of the six substantive coefficients, only two reach statistical significance. In order to improve the statistical precision of the fit, I constrained the coefficients on political awareness to be the same in both the baseline and change models. That is, awareness was constrained to have the same effect on reception in both periods and the same effect on acceptance in both periods. These constraints brought the theoretically important coefficients of awareness to statistical significance at the .05 level, as can be seen in Table 7.4, and did so without producing a significant reduction in the fit of the model to the data (F [2, 707], .43, n.s.). Also, the qualitative fit of the constrained model to the data is as good as the fit of the unconstrained model. It is interesting that hawk-dove attitudes appear about four times more important as a determinant of Central America attitudes than approval of presidential job performance.19 (Since the hawk-dove scale has been standardized and the approval measure runs from -2 to +2, the two variables have approximately the same range.) Thus, it was not Reagan supporters per se who mainly rallied behind U.S. involvement in Central America during the Iran-Contra controversy; it was people having hawkish values. (For additional discussion of this issue, see the appendix to Chapter 8.) The estimated patterns of attitude change in the Central America case are shown in Figure 7.5.20 These patterns, which are derived from the change model in Table 7.4, are highly similar to those for the defense-spending issue. The only important difference is that, for the Central America issue, it is the left-wing group that is resistant to change, whereas in the defense case, the right-wing group is more resistant. Thus, together, the defense and Central America cases show that the model works as well when opinion swings to the right as when it swings to the left. In order to be certain the reader understands what is and is not being shown in Figure 7.5, I present Figure 7.6, which displays the Central America data from a different viewpoint. Rather than show rates of change between two points in time, as in Figure 7.5, it shows absolute levels of support in each period. Thus, 79 percent of the most aware hawks supported greater U.S. involvement in the fall, while 89 percent did so in the summer. This absolute difference of 10 points (89 — 79 = 10) amounts to a conversion rate of about 50 percent for highly aware hawks not already supporting greater U.S. involvement in the fall (10/[100 - 79] = 10/21 = 48 percent). Meanwhile, there is an 11-point shift among hawks scoring just below the median on political awareness (46 - 35 = 11). This 11-point shift represents the conversion of only 17 percent (ll/[100 - 35] = 17 percent) of hawks at this level of political awareness. These conversion rates are what I have plotted in Figure 7.5. The receptionacceptance model, thus, does not deal in the absolute magnitudes of opinion change within subgroups; it deals in conversion rates among the unconverted members of particular groups. The difference is great. Figure 7.6 makes another important point. It might seem odd that the IranContra controversy produced attitude change in a proinvolvement direction. Yet if it were instead asserted that Iran-Contra further polarized public attitudes about U.S. involvement in Central America, the assertion would not seem odd at all. What Figure 7.6 also shows is that a critical effect of the controversy was, in fact, to further polarize hawks and doves. If polarization produced greater overall support for the proinvolvement position, it was because the public was, at the beginning of the Iran-Contra affair, so one-sidedly opposed to U.S. involvement in Central America that polarization entailed gains in support for the pro-involvement position. Before closing the chapter, I should note that the wide confidence intervals for coefficients of the unconstrained model are worrisome, and that I discuss this problem in my concluding evaluation of the model in Chapter 11. In the meantime, let me say briefly that there appear to be two reasons for the problem. They are multicollinearity arising from the fact that awareness must be entered in the model four times (in the reception and acceptance subfunctions of both the baseline and change models), and the dependence of some coefficients on a small subgroup of respondents, namely people who both rank high on political awareness and appear predisposed to resist a given message. Although neither of these problems is a problem with the model itself, they make testing the model difficult. Some steps to maximize the efficiency of future tests are also discussed in Chapter 11.

## CONCLUDING REMARKS 

This chapter has developed some basic principles of attitude change, proposed a simplified model that is broadly consistent with these principles, and undertaken simple tests of the models. The most important of the points made in this chapter is that attitude change may be understood as a two-step process involving, first, reception of persuasive communications and, second, acceptance or nonacceptance of their contents. The reception step in this process depends on the individual's level of political awareness: The greater the person's awareness, the greater his or her chances of receiving - that is, being exposed to and comprehending - a given changeinducing message. The acceptance step is more complicated, but the central idea is that politically aware persons are better able to resist persuasive communications that are inconsistent with their basic values than are less aware persons. The magnitude of the awareness-induced resistance effect depends on the value distance of the individual from the persuasive communication. When the distance is minimal, awareness may have little or no effect in inducing resistance to change, as in the case of Democrats responding to the anti-defense spending message in Figure 7.4. But when the distance is great, awareness is strongly associated with resistance to change, as in the case of Republicans responding to the same liberal message in Figure 7.4. Later chapters will fill out this argument in several ways. One important step that remains to be taken is an examination of the effects of messages of different intensities. As McGuire's analysis of easy-learning and hard-learning situations indicates, the expected pattern of mass attitude change is markedly different when the persuasive message saturates, or nearly saturates, a population, than when the message has so little intensity that it can reach only the most politically aware members of the group. Another complexity concerns the novelty or freshness of the issue that the persuasive message addresses. If the issue is an extremely familiar one, most citizens will have relatively large stores of existing considerations, and this will produce high overall levels of inertial resistance to the message. Such resistance will not only lessen the aggregate amount of attitude change that occurs in response to a message of given intensity, but also alter the pattern of change. Yet another task that remains is to develop evidence that the dynamics of the attitude change model hold at the level of the most basic element of the RAS model, the formation of considerations in response to persuasive communications. I have made specific claims concerning the role of considerations in the change process but have yet to produce direct evidence that the claims are valid. Finally, the model proposed in this chapter assumes that attitude change results from the exposure of the public to a single, dominant flow of communications. This, as I have made clear, is a major simplification. Indeed, in the case of U.S. involvement in Central America, where proinvolvement change took place amid the Iran-Contra scandal, the simplification is so extreme as to be entirely implausible. The assumption of a one-sided information flow is less extreme in the case of defense spending, where, as I was able to report, the flow of information in the media predominantly favored cuts in defense spending. But even here, the public was exposed to some countervalent information from the Reagan administration, which sought to justify its policy of increased spending. Taking full account of the existence of such two-sided information flows is perhaps the most interesting complication to be added to this intitial discussion of attitude change.



